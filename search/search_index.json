{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews. You can also improve topics and articles.</p> <ul> <li>  Interview Questions <p>These are currently most commonly asked interview questions. </p> <p>Questions can be removed if they are no longer popular in interview circles and added as new question banks are released.</p> <ul> <li>DSA (Data Structures &amp; Algorithms)</li> <li>System Design</li> <li>Natural Language Processing (NLP)</li> <li>Probability</li> </ul> </li> <li> Cheat Sheets <p>Distilled down important concepts for your quick reference</p> <ul> <li>Django</li> <li>Flask</li> <li>Hypothesis Tests</li> <li>Keras</li> <li>NumPy</li> <li>Pandas</li> <li>PySpark</li> <li>PyTorch</li> <li>Python</li> <li>Regular Expressions (RegEx)</li> <li>Scikit Learn</li> <li>SQL</li> <li>TensorFlow</li> </ul> </li> <li> ML Algorithms <p>From scratch implementation and documentation of all ML algorithms</p> <ul> <li>ARIMA</li> <li>Activation functions</li> <li>Collaborative Filtering</li> <li>Confusion Matrix</li> <li>DBSCAN</li> <li>Decision Trees</li> <li>Gradient Boosting</li> <li>K-means clustering</li> <li>Linear Regression</li> <li>Logistic Regression</li> <li>Loss Function MAE, RMSE</li> <li>Neural Networks</li> <li>Normal Distribution</li> <li>Normalization Regularisation</li> <li>Overfitting, Underfitting</li> <li>PCA</li> <li>Random Forest</li> <li>Support Vector Machines</li> <li>Unbalanced, Skewed data</li> <li>kNN</li> </ul> </li> <li> Online Resources <p>Most popular and commonly reffered online resources</p> <ul> <li>Online Study Material</li> <li>Popular Blogs</li> </ul> </li> </ul> Current Platform Status  Done Under Development To Do <ul> <li>Cheat-Sheets/Hypothesis-Tests/</li> </ul> <p>Learn about How to contribute?  You can pick anyone, write in <code>.py</code>, <code>.md</code>, <code>.txt</code> or <code>.ipynb</code>; I will format it!</p> <ul> <li>Cheat-Sheets/Django</li> <li>Cheat-Sheets/Flask</li> <li>Cheat-Sheets/Hypothesis-Tests</li> <li>Cheat-Sheets/Keras</li> <li>Cheat-Sheets/NumPy</li> <li>Cheat-Sheets/Pandas</li> <li>Cheat-Sheets/PySpark</li> <li>Cheat-Sheets/PyTorch</li> <li>Cheat-Sheets/Python</li> <li>Cheat-Sheets/RegEx</li> <li>Cheat-Sheets/Sk-learn</li> <li>Cheat-Sheets/SQL</li> <li>Cheat-Sheets/TensorFlow</li> <li>Machine-Learning/ARIMA</li> <li>Machine-Learning/Activation-Functions</li> <li>Machine-Learning/Collaborative-Filtering</li> <li>Machine-Learning/Confusion-Matrix</li> <li>Machine-Learning/DBSCAN</li> <li>Machine-Learning/Decision-Trees</li> <li>Machine-Learning/Gradient-Boosting</li> <li>Machine-Learning/K-means-Clustering</li> <li>Machine-Learning/Linear-Regression</li> <li>Machine-Learning/Logistic-Regression</li> <li>Machine-Learning/Loss-Function-MAE-RMSE</li> <li>Machine-Learning/Neural-Networks</li> <li>Machine-Learning/Normal-Distribution</li> <li>Machine-Learning/Normalization-Regularisation</li> <li>Machine-Learning/Overfitting-Underfitting</li> <li>Machine-Learning/PCA</li> <li>Machine-Learning/Random-Forest</li> <li>Machine-Learning/Support-Vector-Machines</li> <li>Machine-Learning/Unbalanced-Skewed-Data</li> <li>Machine-Learning/kNN</li> <li>Online-Material/Online-Material-for-Learning</li> <li>Online-Material/Popular-Blogs</li> <li>Interview-Questions/DSA</li> <li>Interview-Questions/System-Design</li> <li>Interview-Questions/Natural-Language-Processing</li> <li>Interview-Questions/Probability</li> </ul> <ul> <li>:: Project Maintainer</li> <li> All Contributors list</li> <li> AGPL-3.0 license</li> <li> Reach Out</li> </ul>"},{"location":"Contribute/","title":"Contributions to singhsidhukuldeep.github.io","text":"<p>For any correspondence please check contact</p> <p>Detailed step by step contributions guide coming soon!</p> <p>For now, plese open a discussion here for anything!</p> <p>List of things to contribute!</p> <p>Thank you, Kuldeep</p>"},{"location":"Introduction/","title":"Home","text":""},{"location":"Introduction/#introduction","title":"Introduction","text":"<p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews.</p>"},{"location":"Introduction/#contribute-to-the-platform","title":"Contribute to the platform","text":"<p>Contribution in any form will be deeply appreciated. \ud83d\ude4f</p>"},{"location":"Introduction/#add-questions","title":"Add questions","text":"<p>\u2753 Add your questions here. Please ensure to provide a detailed description to allow your fellow contributors to understand your questions and answer them to your satisfaction.</p> <p></p> <p>\ud83e\udd1d Please note that as of now, you cannot directly add a question via a pull request. This will help us to maintain the quality of the content for you.</p>"},{"location":"Introduction/#add-answerstopics","title":"Add answers/topics","text":"<p>\ud83d\udcdd These are the answers/topics that need your help at the moment</p> <ul> <li> Add documentation for the project</li> <li> Online Material for Learning</li> <li> Suggested Learning Paths</li> <li> Cheat Sheets<ul> <li> Django</li> <li> Flask</li> <li> Numpy</li> <li> Pandas</li> <li> PySpark</li> <li> Python</li> <li> RegEx</li> <li> SQL</li> </ul> </li> <li> NLP Interview Questions</li> <li> Add python common DSA interview questions</li> <li> Add Major ML topics<ul> <li> Linear Regression </li> <li> Logistic Regression </li> <li> SVM </li> <li> Random Forest </li> <li> Gradient boosting </li> <li> PCA </li> <li> Collaborative Filtering </li> <li> K-means clustering </li> <li> kNN </li> <li> ARIMA </li> <li> Neural Networks </li> <li> Decision Trees </li> <li> Overfitting, Underfitting</li> <li> Unbalanced, Skewed data</li> <li> Activation functions relu/ leaky relu</li> <li> Normalization</li> <li> DBSCAN </li> <li> Normal Distribution </li> <li> Precision, Recall </li> <li> Loss Function MAE, RMSE </li> </ul> </li> <li> Add Pandas questions</li> <li> Add NumPy questions</li> <li> Add TensorFlow questions</li> <li> Add PyTorch questions</li> <li> Add list of learning resources</li> </ul>"},{"location":"Introduction/#reportsolve-issues","title":"Report/Solve Issues","text":"<p>\ud83d\udd27 To report any issues find me on LinkedIn or raise an issue on GitHub.</p> <p>\ud83d\udee0 You can also solve existing issues on GitHub and create a pull request.</p>"},{"location":"Introduction/#say-thanks","title":"Say Thanks","text":"<p>\ud83d\ude0a If this platform helped you in any way, it would be great if you could share it with others.</p> <p> </p> <pre><code>Check out this \ud83d\udc47 platform \ud83d\udc47 for data science content:\n\ud83d\udc49 https://singhsidhukuldeep.github.io/data-science-interview-prep/ \ud83d\udc48\n</code></pre> <p>You can also star the repository on GitHub    and watch-out for any updates </p>"},{"location":"Introduction/#features","title":"Features","text":"<ul> <li> <p>\ud83c\udfa8 Beautiful: The design is built on top of most popular libraries like MkDocs and material which allows the platform to be responsive and to work on all sorts of devices \u2013 from mobile phones to wide-screens. The underlying fluid layout will always adapt perfectly to the available screen space.</p> </li> <li> <p>\ud83e\uddd0 Searchable: almost magically, all the content on the website is searchable without any further ado. The built-in search \u2013 server-less \u2013 is fast and accurate in responses to any of the queries.</p> </li> <li> <p>\ud83d\ude4c Accessible:</p> <ul> <li>Easy to use: \ud83d\udc4c The website is hosted on github-pages and is free and open to use to over 40 million users of GitHub in 100+ countries.</li> <li>Easy to contribute: \ud83e\udd1d The website embodies the concept of collaboration to the latter. Allowing anyone to add/improve the content. To make contributing easy, everything is written in MarkDown and then compiled to beautiful html.</li> </ul> </li> </ul>"},{"location":"Introduction/#setup","title":"Setup","text":"<p>No setup is required for usage of the platform</p> <p>Important: It is strongly advised to use virtual environment and not change anything in <code>gh-pages</code></p>"},{"location":"Introduction/#linux-systems","title":"<code>Linux</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nsource venv/bin/activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>deactivate\n</code></pre>"},{"location":"Introduction/#windows-systems","title":"<code>Windows</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nvenv\\Scripts\\activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>venv\\Scripts\\deactivate\n</code></pre>"},{"location":"Introduction/#to-install-the-latest","title":"To install the latest","text":"<pre><code>pip3 install mkdocs\npip3 install mkdocs-material\npip3 install mkdocs-minify-plugin\npip3 install mkdocs-git-revision-date-localized-plugin\n</code></pre>"},{"location":"Introduction/#useful-commands","title":"Useful Commands","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Use\u00a0<code>mkdocs gh-deploy --help</code>\u00a0to get a full list of options available for the\u00a0<code>gh-deploy</code>\u00a0command.     Be aware that you will not be able to review the built site before it is pushed to GitHub. Therefore, you may want to verify any changes you make to the docs beforehand by using the\u00a0<code>build</code>\u00a0or\u00a0<code>serve</code>\u00a0commands and reviewing the built files locally.</li> <li><code>mkdocs new [dir-name]</code> - Create a new project. No need to create a new project</li> </ul>"},{"location":"Introduction/#useful-documents","title":"Useful Documents","text":"<ul> <li> <p>\ud83d\udcd1 MkDocs: </p> <ul> <li>GitHub: https://github.com/mkdocs/mkdocs</li> <li>Documentation: https://www.mkdocs.org/</li> </ul> </li> <li> <p>\ud83c\udfa8 Theme: </p> <ul> <li>GitHub: https://github.com/squidfunk/mkdocs-material</li> <li>Documentation: https://squidfunk.github.io/mkdocs-material/getting-started/</li> </ul> </li> </ul>"},{"location":"Introduction/#faq","title":"FAQ","text":"<ul> <li> <p>Can I filter questions based on companies? \ud83e\udd2a</p> <p>As much as this platform aims to help you with your interview preparation, it is not a short-cut to crack one. Think of this platform as a practicing field to help you sharpen your skills for your interview processes. However, for your convenience we have sorted all the questions by topics for you. \ud83e\udd13</p> <p>This doesn't mean that such feature won't be added in the future.  \"Never say Never\"</p> <p>But as of now there is neither plan nor data to do so. \ud83d\ude22</p> </li> <li> <p>Why is this platform free? \ud83e\udd17</p> <p>Currently there is no major cost involved in maintaining this platform other than time and effort that is put in by every contributor.  If you want to help you can contribute here. </p> <p>If you still want to pay for something that is free, we would request you to donate it to a charity of your choice instead. \ud83d\ude07</p> </li> </ul>"},{"location":"Introduction/#credits","title":"Credits","text":""},{"location":"Introduction/#maintained-by","title":"Maintained by","text":"<p>\ud83d\udc68\u200d\ud83c\udf93 Kuldeep Singh Sidhu </p> <p>Github: github/singhsidhukuldeep <code>https://github.com/singhsidhukuldeep</code></p> <p>Website: Kuldeep Singh Sidhu (Website) <code>http://kuldeepsinghsidhu.com</code></p> <p>LinkedIn: Kuldeep Singh Sidhu (LinkedIn) <code>https://www.linkedin.com/in/singhsidhukuldeep/</code></p>"},{"location":"Introduction/#contributors","title":"Contributors","text":"<p>\ud83d\ude0e The full list of all the contributors is available here</p>"},{"location":"Introduction/#current-status","title":"Current Status","text":""},{"location":"contact/","title":"Contact for https://singhsidhukuldeep.github.io","text":"<p>Welcome to https://singhsidhukuldeep.github.io/ </p> <p>For any information, request or official correspondence please email to: singhsidhukuldeep@gmail.com</p> <p>Mailing Address:</p> <p>Kuldeep Singh Sidhu</p> <p>Street No 4, Malviya Nagar Bathinda, Punjab, 151001 India</p>"},{"location":"contact/#follow-on-social-media","title":"Follow on Social Media","text":"Platform Link GitHub https://github.com/singhsidhukuldeep LinkedIn https://www.linkedin.com/in/singhsidhukuldeep/ Twitter (X) https://twitter.com/kuldeep_s_s HuggingFace https://huggingface.co/singhsidhukuldeep StackOverflow https://stackoverflow.com/users/7182350 Website http://kuldeepsinghsidhu.com/"},{"location":"privacy/","title":"Privacy Policy for https://singhsidhukuldeep.github.io","text":""},{"location":"privacy/#introduction","title":"Introduction","text":"<p>Welcome to https://singhsidhukuldeep.github.io/ (the \"Website\"). Your privacy is important to us, and we are committed to protecting the personal information you share with us. This Privacy Policy explains how we collect, use, and disclose your information, and our commitment to ensuring that your personal data is handled with care and security.</p> <p>This policy complies with the General Data Protection Regulation (GDPR), ePrivacy Directive (EPD), California Privacy Rights Act (CPRA), Colorado Privacy Act (CPA), Virginia Consumer Data Protection Act (VCDPA), and Brazil's Lei Geral de Prote\u00e7\u00e3o de Dados (LGPD).</p>"},{"location":"privacy/#information-we-collect","title":"Information We Collect","text":""},{"location":"privacy/#personal-information","title":"Personal Information","text":"<p>We may collect personally identifiable information about you, such as:</p> <ul> <li>Name</li> <li>Email address</li> <li>IP address</li> <li>Other information you voluntarily provide through contact forms or interactions with the Website</li> </ul>"},{"location":"privacy/#non-personal-information","title":"Non-Personal Information","text":"<p>We may also collect non-personal information such as:</p> <ul> <li>Browser type</li> <li>Language preference</li> <li>Referring site</li> <li>Date and time of each visitor request</li> <li>Aggregated data on how visitors use the Website</li> </ul>"},{"location":"privacy/#cookies-and-web-beacons","title":"Cookies and Web Beacons","text":"<p>Our Website uses cookies to enhance your experience. A cookie is a small file that is placed on your device when you visit our Website. Cookies help us to:</p> <ul> <li>Remember your preferences and settings</li> <li>Understand how you interact with our Website</li> <li>Track and analyze usage patterns</li> </ul> <p>You can disable cookies through your browser settings; however, doing so may affect your ability to access certain features of the Website.</p>"},{"location":"privacy/#google-adsense","title":"Google AdSense","text":"<p>We use Google AdSense to display advertisements on our Website. Google AdSense may use cookies and web beacons to collect information about your interaction with the ads displayed on our Website. This information may include:</p> <ul> <li>Your IP address</li> <li>The type of browser you use</li> <li>The pages you visit on our Website</li> </ul> <p>Google may use this information to show you personalized ads based on your interests and browsing history. For more information on how Google uses your data, please visit the Google Privacy &amp; Terms page.</p>"},{"location":"privacy/#legal-bases-for-processing-your-data-gdpr-compliance","title":"Legal Bases for Processing Your Data (GDPR Compliance)","text":"<p>We process your personal data under the following legal bases:</p> <ul> <li>Consent: When you have given explicit consent for us to process your data for specific purposes.</li> <li>Contract: When processing your data is necessary to fulfill a contract with you or to take steps at your request before entering into a contract.</li> <li>Legitimate Interests: When the processing is necessary for our legitimate interests, such as improving our services, provided these are not overridden by your rights.</li> <li>Compliance with Legal Obligations: When we need to process your data to comply with a legal obligation.</li> </ul>"},{"location":"privacy/#how-your-data-will-be-used-to-show-ads","title":"How Your Data Will Be Used to Show Ads","text":"<p>We work with third-party vendors, including Google, to serve ads on our Website. These vendors use cookies and similar technologies to collect and use data about your visits to this and other websites to show you ads that are more relevant to your interests.</p>"},{"location":"privacy/#types-of-data-used","title":"Types of Data Used","text":"<p>The data used to show you ads may include:</p> <ul> <li>Demographic Information: Age, gender, and other demographic details</li> <li>Location Data: Approximate geographical location based on your IP address</li> <li>Behavioral Data: Your browsing behavior, such as pages visited, links clicked, and time spent on our Website</li> <li>Interests and Preferences: Based on your browsing history, the types of ads you interact with, and your preferences across websites</li> </ul>"},{"location":"privacy/#purpose-of-data-usage","title":"Purpose of Data Usage","text":"<p>The primary purpose of collecting and using this data is to:</p> <ul> <li>Serve ads that are relevant and tailored to your interests</li> <li>Improve ad targeting and effectiveness</li> <li>Analyze and optimize the performance of ads on our Website</li> </ul>"},{"location":"privacy/#opting-out-of-personalized-ads","title":"Opting Out of Personalized Ads","text":"<p>You can opt out of personalized ads by adjusting your ad settings with Google and other third-party vendors. For more information on how to opt out of personalized ads, please visit the Google Ads Settings page and review the options available to manage your preferences.</p>"},{"location":"privacy/#data-subject-rights-gdpr-cpra-cpa-vcdpa-lgpd-compliance","title":"Data Subject Rights (GDPR, CPRA, CPA, VCDPA, LGPD Compliance)","text":"<p>Depending on your jurisdiction, you have the following rights regarding your personal data:</p>"},{"location":"privacy/#right-to-access","title":"Right to Access","text":"<p>You have the right to request access to the personal data we hold about you and to receive a copy of this data.</p>"},{"location":"privacy/#right-to-rectification","title":"Right to Rectification","text":"<p>You have the right to request that we correct any inaccuracies in the personal data we hold about you.</p>"},{"location":"privacy/#right-to-erasure-right-to-be-forgotten","title":"Right to Erasure (Right to Be Forgotten)","text":"<p>You have the right to request that we delete your personal data, subject to certain conditions and legal obligations.</p>"},{"location":"privacy/#right-to-restriction-of-processing","title":"Right to Restriction of Processing","text":"<p>You have the right to request that we restrict the processing of your personal data in certain circumstances, such as when you contest the accuracy of the data.</p>"},{"location":"privacy/#right-to-data-portability","title":"Right to Data Portability","text":"<p>You have the right to receive your personal data in a structured, commonly used, and machine-readable format and to transmit this data to another controller.</p>"},{"location":"privacy/#right-to-object","title":"Right to Object","text":"<p>You have the right to object to the processing of your personal data based on legitimate interests or for direct marketing purposes.</p>"},{"location":"privacy/#right-to-withdraw-consent","title":"Right to Withdraw Consent","text":"<p>Where we rely on your consent to process your personal data, you have the right to withdraw your consent at any time.</p>"},{"location":"privacy/#right-to-non-discrimination-cpra-compliance","title":"Right to Non-Discrimination (CPRA Compliance)","text":"<p>We will not discriminate against you for exercising any of your privacy rights under CPRA or any other applicable laws.</p>"},{"location":"privacy/#exercising-your-rights","title":"Exercising Your Rights","text":"<p>To exercise any of these rights, please contact us at:</p> <p>Email: singhsidhukuldeep@gmail.com</p> <p>We will respond to your request within the timeframes required by applicable law.</p>"},{"location":"privacy/#how-we-use-your-information","title":"How We Use Your Information","text":"<p>We use the information collected from you to:</p> <ul> <li>Improve the content and functionality of our Website</li> <li>Display relevant advertisements through Google AdSense and other ad networks</li> <li>Respond to your inquiries and provide customer support</li> <li>Analyze usage patterns and improve our services</li> </ul>"},{"location":"privacy/#data-sharing-and-disclosure","title":"Data Sharing and Disclosure","text":""},{"location":"privacy/#third-party-service-providers","title":"Third-Party Service Providers","text":"<p>We may share your personal data with third-party service providers who assist us in operating our Website, conducting our business, or servicing you, as long as these parties agree to keep this information confidential.</p>"},{"location":"privacy/#legal-obligations","title":"Legal Obligations","text":"<p>We may disclose your personal data when required by law or to comply with legal processes, such as a court order or subpoena.</p>"},{"location":"privacy/#business-transfers","title":"Business Transfers","text":"<p>In the event of a merger, acquisition, or sale of all or a portion of our assets, your personal data may be transferred to the acquiring entity.</p>"},{"location":"privacy/#data-retention","title":"Data Retention","text":"<p>We will retain your personal data only for as long as necessary to fulfill the purposes outlined in this Privacy Policy unless a longer retention period is required or permitted by law.</p>"},{"location":"privacy/#data-security","title":"Data Security","text":"<p>We take reasonable measures to protect your information from unauthorized access, alteration, disclosure, or destruction. However, no method of transmission over the internet or electronic storage is 100% secure, and we cannot guarantee absolute security.</p>"},{"location":"privacy/#cross-border-data-transfers","title":"Cross-Border Data Transfers","text":"<p>Your personal data may be transferred to, and processed in, countries other than the country in which you are resident. These countries may have data protection laws that are different from the laws of your country.</p> <p>Where we transfer your personal data to other countries, we will take appropriate measures to ensure that your personal data remains protected in accordance with this Privacy Policy and applicable data protection laws.</p>"},{"location":"privacy/#your-consent","title":"Your Consent","text":"<p>By using our Website, you consent to our Privacy Policy and agree to its terms.</p>"},{"location":"privacy/#changes-to-this-privacy-policy","title":"Changes to This Privacy Policy","text":"<p>We may update this Privacy Policy from time to time. We will notify you of any changes by posting the new Privacy Policy on this page. You are advised to review this Privacy Policy periodically for any changes.</p>"},{"location":"privacy/#contact-us","title":"Contact Us","text":"<p>If you have any questions about this Privacy Policy, or if you would like to exercise your rights under GDPR, CPRA, CPA, VCDPA, or LGPD, please contact us at:</p> <p>Email: singhsidhukuldeep@gmail.com</p> <p>Mailing Address:</p> <p>Kuldeep Singh Sidhu</p> <p>Street No 4, Malviya Nagar Bathinda, Punjab, 151001 India</p>"},{"location":"projects/","title":"Projects","text":""},{"location":"projects/#introduction","title":"Introduction","text":"<p>These are the projects that you can take inspiration from and try to improve on them. \u270d\ufe0f</p> <p></p>"},{"location":"projects/#popular-sources","title":"Popular Sources","text":""},{"location":"projects/#list-of-projects","title":"List of projects","text":""},{"location":"projects/#natural-language-processing-nlp","title":"Natural Language processing (NLP)","text":"Title Description Source Author Text Classification with Facebook fasttext Building the User Review Model with fastText (Text Classification) with response time of less than one second Kuldeep Singh Sidhu Chat-bot using ChatterBot ChatterBot is a Python library that makes it easy to generate automated responses to a user\u2019s input. Kuldeep Singh Sidhu Text Summarizer Comparing state of the art models for text summary generation Kuldeep Singh Sidhu NLP with Spacy Building NLP pipeline using Spacy Kuldeep Singh Sidhu"},{"location":"projects/#recommendation-engine","title":"Recommendation Engine","text":"Title Description Source Author Recommendation Engine with Surprise Comparing different recommendation systems algorithms like SVD, SVDpp (Matrix Factorization), KNN Baseline, KNN Basic, KNN Means, KNN ZScore), Baseline, Co Clustering Kuldeep Singh Sidhu"},{"location":"projects/#image-processing","title":"Image Processing","text":"Title Description Source Author Facial Landmarks Using Dlib, a library capable of giving you 68 points (land marks) of the face. Kuldeep Singh Sidhu"},{"location":"projects/#reinforcement-learning","title":"Reinforcement Learning","text":"Title Description Source Author Google Dopamine Dopamine is a research framework for fast prototyping of reinforcement learning algorithms. Kuldeep Singh Sidhu Tic Tac Toe Training a computer to play Tic Tac Toe using reinforcement learning algorithms. Kuldeep Singh Sidhu"},{"location":"projects/#others","title":"Others","text":"Title Description Source Author TensorFlow Eager Execution Eager Execution (EE) enables you to run operations immediately. Kuldeep Singh Sidhu"},{"location":"Cheat-Sheets/Hypothesis-Tests/","title":"Hypothesis Tests in Python","text":"<ul> <li>Hypothesis Tests in Python<ul> <li>Normality Tests<ul> <li>Shapiro-Wilk Test</li> <li>D\u2019Agostino\u2019s K^2 Test</li> <li>Anderson-Darling Test</li> </ul> </li> <li>Correlation Tests<ul> <li>Pearson\u2019s Correlation Coefficient</li> <li>Spearman\u2019s Rank Correlation</li> <li>Kendall\u2019s Rank Correlation</li> <li>Chi-Squared Test</li> </ul> </li> <li>Stationary Tests<ul> <li>Augmented Dickey-Fuller Unit Root Test</li> <li>Kwiatkowski-Phillips-Schmidt-Shin</li> </ul> </li> <li>Parametric Statistical Hypothesis Tests<ul> <li>Student\u2019s t-test</li> <li>Paired Student\u2019s t-test</li> <li>Analysis of Variance Test (ANOVA)</li> <li>Repeated Measures ANOVA Test</li> </ul> </li> <li>Nonparametric Statistical Hypothesis Tests<ul> <li>Mann-Whitney U Test</li> <li>Wilcoxon Signed-Rank Test</li> <li>Kruskal-Wallis H Test</li> <li>Friedman Test</li> </ul> </li> <li>Equality of variance test<ul> <li>Levene's test</li> </ul> </li> </ul> </li> </ul> <p>A\u00a0statistical hypothesis test\u00a0is a method of\u00a0statistical inference\u00a0used to decide whether the data at hand sufficiently support a particular hypothesis. Hypothesis testing allows us to make probabilistic statements about population parameters.</p> <p>Few Notes:</p> <ul> <li>When it comes to assumptions such as the expected distribution of data or sample size, the results of a given test are likely to degrade gracefully rather than become immediately unusable if an assumption is violated.</li> <li>Generally, data samples need to be representative of the domain and large enough to expose their distribution to analysis.</li> <li>In some cases, the data can be corrected to meet the assumptions, such as correcting a nearly normal distribution to be normal by removing outliers, or using a correction to the degrees of freedom in a statistical test when samples have differing variance, to name two examples.</li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#normality-tests","title":"Normality Tests","text":"<p>This section lists statistical tests that you can use to check if your data has a Gaussian distribution.</p> <p>Gaussian distribution (also known as normal distribution) is a bell-shaped curve.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#shapiro-wilk-test","title":"Shapiro-Wilk Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Shapiro-Wilk Normality Test\nfrom scipy.stats import shapiro\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nstat, p = shapiro(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.shapiro</li> <li>Shapiro-Wilk test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#dagostinos-k2-test","title":"D\u2019Agostino\u2019s K^2 Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the D'Agostino's K^2 Normality Test\nfrom scipy.stats import normaltest\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nstat, p = normaltest(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.normaltest</li> <li>D'Agostino's K-squared test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#anderson-darling-test","title":"Anderson-Darling Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Anderson-Darling Normality Test\nfrom scipy.stats import anderson\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nresult = anderson(data)\nprint('stat=%.3f' % (result.statistic))\nfor i in range(len(result.critical_values)):\n    sl, cv = result.significance_level[i], result.critical_values[i]\n    if result.statistic &lt; cv:\n        print('Probably Gaussian at the %.1f%% level' % (sl))\n    else:\n        print('Probably not Gaussian at the %.1f%% level' % (sl))\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.anderson</li> <li>Anderson-Darling test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#correlation-tests","title":"Correlation Tests","text":"<p>This section lists statistical tests that you can use to check if two samples are related.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#pearsons-correlation-coefficient","title":"Pearson\u2019s Correlation Coefficient","text":"<p>Tests whether two samples have a linear relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Pearson's Correlation test\nfrom scipy.stats import pearsonr\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = pearsonr(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.pearsonr</li> <li>Pearson's correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#spearmans-rank-correlation","title":"Spearman\u2019s Rank Correlation","text":"<p>Tests whether two samples have a monotonic relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Spearman's Rank Correlation Test\nfrom scipy.stats import spearmanr\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = spearmanr(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.spearmanr</li> <li>Spearman's rank correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kendalls-rank-correlation","title":"Kendall\u2019s Rank Correlation","text":"<p>Tests whether two samples have a monotonic relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kendall's Rank Correlation Test\nfrom scipy.stats import kendalltau\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = kendalltau(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.kendalltau</li> <li>Kendall rank correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#chi-squared-test","title":"Chi-Squared Test","text":"<p>Tests whether two categorical variables are related or independent.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations used in the calculation of the contingency table are independent.</li> <li>25 or more examples in each cell of the contingency table.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Chi-Squared Test\nfrom scipy.stats import chi2_contingency\ntable = [[10, 20, 30],[6,  9,  17]]\nstat, p, dof, expected = chi2_contingency(table)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.chi2_contingency</li> <li>Chi-Squared test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#stationary-tests","title":"Stationary Tests","text":"<p>This section lists statistical tests that you can use to check if a time series is stationary or not.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#augmented-dickey-fuller-unit-root-test","title":"Augmented Dickey-Fuller Unit Root Test","text":"<p>Tests whether a time series has a unit root, e.g. has a trend or more generally is autoregressive.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in are temporally ordered.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: a unit root is present (series is non-stationary).</li> <li>H1: a unit root is not present (series is stationary).</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Augmented Dickey-Fuller unit root test\nfrom statsmodels.tsa.stattools import adfuller\ndata = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nstat, p, lags, obs, crit, t = adfuller(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably not Stationary')\nelse:\n    print('Probably Stationary')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>statsmodels.tsa.stattools.adfuller API.</li> <li>Augmented Dickey--Fuller test, Wikipedia.</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kwiatkowski-phillips-schmidt-shin","title":"Kwiatkowski-Phillips-Schmidt-Shin","text":"<p>Tests whether a time series is trend stationary or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in are temporally ordered.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the time series is trend-stationary.</li> <li>H1: the time series is not trend-stationary.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kwiatkowski-Phillips-Schmidt-Shin test\nfrom statsmodels.tsa.stattools import kpss\ndata = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nstat, p, lags, crit = kpss(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Stationary')\nelse:\n    print('Probably not Stationary')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>statsmodels.tsa.stattools.kpss API.</li> <li>KPSS test, Wikipedia.</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#parametric-statistical-hypothesis-tests","title":"Parametric Statistical Hypothesis Tests","text":"<p>This section lists statistical tests that you can use to compare data samples.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#students-t-test","title":"Student\u2019s t-test","text":"<p>Tests whether the means of two independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Student's t-test\nfrom scipy.stats import ttest_ind\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = ttest_ind(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.ttest_ind</li> <li>Student's t-test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#paired-students-t-test","title":"Paired Student\u2019s t-test","text":"<p>Tests whether the means of two independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Paired Student's t-test\nfrom scipy.stats import ttest_rel\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = ttest_rel(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.ttest_rel</li> <li>Student's t-test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#analysis-of-variance-test-anova","title":"Analysis of Variance Test (ANOVA)","text":"<p>Tests whether the means of two or more independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Analysis of Variance Test\nfrom scipy.stats import f_oneway\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\ndata3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\nstat, p = f_oneway(data1, data2, data3)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.f_oneway</li> <li>Analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#repeated-measures-anova-test","title":"Repeated Measures ANOVA Test","text":"<p>Tests whether the means of two or more paired samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: one or more of the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Currently not supported in Python. :(\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>Analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#nonparametric-statistical-hypothesis-tests","title":"Nonparametric Statistical Hypothesis Tests","text":"<p>In Non-Parametric tests, we don't make any assumption about the parameters for the given population or the population we are studying. In fact, these tests don't depend on the population. Hence, there is no fixed set of parameters is available, and also there is no distribution (normal distribution, etc.)</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#mann-whitney-u-test","title":"Mann-Whitney U Test","text":"<p>Tests whether the distributions of two independent samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of both samples are equal.</li> <li>H1: the distributions of both samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Mann-Whitney U Test\nfrom scipy.stats import mannwhitneyu\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = mannwhitneyu(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.mannwhitneyu</li> <li>Mann-Whitney U test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#wilcoxon-signed-rank-test","title":"Wilcoxon Signed-Rank Test","text":"<p>Tests whether the distributions of two paired samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of both samples are equal.</li> <li>H1: the distributions of both samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Wilcoxon Signed-Rank Test\nfrom scipy.stats import wilcoxon\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = wilcoxon(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.wilcoxon</li> <li>Wilcoxon signed-rank test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kruskal-wallis-h-test","title":"Kruskal-Wallis H Test","text":"<p>Tests whether the distributions of two or more independent samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of all samples are equal.</li> <li>H1: the distributions of one or more samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kruskal-Wallis H Test\nfrom scipy.stats import kruskal\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = kruskal(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.kruskal</li> <li>Kruskal-Wallis one-way analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#friedman-test","title":"Friedman Test","text":"<p>Tests whether the distributions of two or more paired samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of all samples are equal.</li> <li>H1: the distributions of one or more samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Friedman Test\nfrom scipy.stats import friedmanchisquare\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\ndata3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\nstat, p = friedmanchisquare(data1, data2, data3)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.friedmanchisquare</li> <li>Friedman test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#equality-of-variance-test","title":"Equality of variance test","text":"<p>Test is used to assess the equality of variance between two different samples.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#levenes-test","title":"Levene's test","text":"<p>Levene\u2019s test is used to assess the equality of variance between two or more different samples.</p> <ul> <li> <p>Assumptions</p> <ul> <li>The samples from the populations under consideration are independent.</li> <li>The populations under consideration are approximately normally distributed.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: All the samples variances are equal</li> <li>H1: At least one variance is different from the rest</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Levene's test\nfrom scipy.stats import levene\na = [8.88, 9.12, 9.04, 8.98, 9.00, 9.08, 9.01, 8.85, 9.06, 8.99]\nb = [8.88, 8.95, 9.29, 9.44, 9.15, 9.58, 8.36, 9.18, 8.67, 9.05]\nc = [8.95, 9.12, 8.95, 8.85, 9.03, 8.84, 9.07, 8.98, 8.86, 8.98]\nstat, p = levene(a, b, c)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same variances')\nelse:\n    print('Probably at least one variance is different from the rest')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.levene</li> <li>Levene's test on Wikipedia</li> </ul> </li> </ul> <p>Source: https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/</p>"},{"location":"Cheat-Sheets/NumPy/","title":"NumPy","text":"In\u00a0[1]: Copied! <pre>import numpy as np  # Importing NumPy\nnp.__version__  # Check version of NumPy\n</pre> import numpy as np  # Importing NumPy np.__version__  # Check version of NumPy Out[1]: <pre>'1.26.4'</pre> In\u00a0[2]: Copied! <pre>arr1 = np.array([1, 2, 3])\narr1\n</pre> arr1 = np.array([1, 2, 3]) arr1 Out[2]: <pre>array([1, 2, 3])</pre> In\u00a0[3]: Copied! <pre>arr2 = np.array((1, 2, 3))\narr2\n</pre> arr2 = np.array((1, 2, 3)) arr2 Out[3]: <pre>array([1, 2, 3])</pre> In\u00a0[4]: Copied! <pre>arr3 = np.frombuffer(b'Hello World', dtype='S1')\narr3\n</pre> arr3 = np.frombuffer(b'Hello World', dtype='S1') arr3 Out[4]: <pre>array([b'H', b'e', b'l', b'l', b'o', b' ', b'W', b'o', b'r', b'l', b'd'],\n      dtype='|S1')</pre> In\u00a0[5]: Copied! <pre>arr_zeros = np.zeros((2, 3))  # 2x3 array of zeros\narr_zeros\n</pre> arr_zeros = np.zeros((2, 3))  # 2x3 array of zeros arr_zeros Out[5]: <pre>array([[0., 0., 0.],\n       [0., 0., 0.]])</pre> In\u00a0[6]: Copied! <pre>arr_ones = np.ones((2, 3))  # 2x3 array of ones\narr_ones\n</pre> arr_ones = np.ones((2, 3))  # 2x3 array of ones arr_ones Out[6]: <pre>array([[1., 1., 1.],\n       [1., 1., 1.]])</pre> In\u00a0[7]: Copied! <pre>arr_empty = np.empty((2, 3))  # 2x3 empty array\narr_empty\n</pre> arr_empty = np.empty((2, 3))  # 2x3 empty array arr_empty Out[7]: <pre>array([[1., 1., 1.],\n       [1., 1., 1.]])</pre> In\u00a0[8]: Copied! <pre>arr_range = np.arange(0, 10, 2)  # Array from 0 to 9 with step 2\narr_range\n</pre> arr_range = np.arange(0, 10, 2)  # Array from 0 to 9 with step 2 arr_range Out[8]: <pre>array([0, 2, 4, 6, 8])</pre> In\u00a0[9]: Copied! <pre>arr_linspace = np.linspace(0, 1, 5)  # 5 equally spaced numbers from 0 to 1\narr_linspace\n</pre> arr_linspace = np.linspace(0, 1, 5)  # 5 equally spaced numbers from 0 to 1 arr_linspace Out[9]: <pre>array([0.  , 0.25, 0.5 , 0.75, 1.  ])</pre> In\u00a0[10]: Copied! <pre>arr_random = np.random.rand(2, 3)  # 2x3 array with random numbers between 0 and 1\narr_random\n</pre> arr_random = np.random.rand(2, 3)  # 2x3 array with random numbers between 0 and 1 arr_random Out[10]: <pre>array([[0.78160058, 0.52687888, 0.29604995],\n       [0.63947724, 0.99231115, 0.3488577 ]])</pre> In\u00a0[11]: Copied! <pre>arr_identity = np.eye(3)  # 3x3 identity matrix\narr_identity\n</pre> arr_identity = np.eye(3)  # 3x3 identity matrix arr_identity Out[11]: <pre>array([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])</pre> In\u00a0[12]: Copied! <pre>arr_diag = np.diag([1, 2, 3])  # Diagonal matrix from a list\narr_diag\n</pre> arr_diag = np.diag([1, 2, 3])  # Diagonal matrix from a list arr_diag Out[12]: <pre>array([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])</pre> In\u00a0[13]: Copied! <pre>dt = np.dtype([('age', np.int32), ('name', np.str_, 10)])\narr_structured = np.array([(21, 'Alice'), (25, 'Bob')], dtype=dt)\narr_structured\n</pre> dt = np.dtype([('age', np.int32), ('name', np.str_, 10)]) arr_structured = np.array([(21, 'Alice'), (25, 'Bob')], dtype=dt) arr_structured Out[13]: <pre>array([(21, 'Alice'), (25, 'Bob')],\n      dtype=[('age', '&lt;i4'), ('name', '&lt;U10')])</pre> In\u00a0[14]: Copied! <pre>arr_full = np.full((2, 3), 7)  # Create a 2x3 array filled with the value 7\narr_full\n</pre> arr_full = np.full((2, 3), 7)  # Create a 2x3 array filled with the value 7 arr_full Out[14]: <pre>array([[7, 7, 7],\n       [7, 7, 7]])</pre> In\u00a0[15]: Copied! <pre>arr_tile = np.tile([1, 2], (2, 3))  # Repeat [1, 2] in a 2x3 grid\narr_tile\n</pre> arr_tile = np.tile([1, 2], (2, 3))  # Repeat [1, 2] in a 2x3 grid arr_tile Out[15]: <pre>array([[1, 2, 1, 2, 1, 2],\n       [1, 2, 1, 2, 1, 2]])</pre> In\u00a0[16]: Copied! <pre>arr1.shape  # Dimensions of the array\n</pre> arr1.shape  # Dimensions of the array Out[16]: <pre>(3,)</pre> In\u00a0[17]: Copied! <pre>arr1.size  # Total number of elements\n</pre> arr1.size  # Total number of elements Out[17]: <pre>3</pre> In\u00a0[18]: Copied! <pre>arr1.ndim  # Number of dimensions\n</pre> arr1.ndim  # Number of dimensions Out[18]: <pre>1</pre> In\u00a0[19]: Copied! <pre>arr1.dtype  # Data type of elements\n</pre> arr1.dtype  # Data type of elements Out[19]: <pre>dtype('int64')</pre> In\u00a0[20]: Copied! <pre>arr1_float = arr1.astype(float)  # Convert to another type\narr1_float\n</pre> arr1_float = arr1.astype(float)  # Convert to another type arr1_float Out[20]: <pre>array([1., 2., 3.])</pre> In\u00a0[21]: Copied! <pre>arr1.itemsize  # Size of one element in bytes\n</pre> arr1.itemsize  # Size of one element in bytes Out[21]: <pre>8</pre> In\u00a0[22]: Copied! <pre>arr1.nbytes  # Total memory used by array\n</pre> arr1.nbytes  # Total memory used by array Out[22]: <pre>24</pre> In\u00a0[23]: Copied! <pre>arr1.flags  # Memory layout information\n</pre> arr1.flags  # Memory layout information Out[23]: <pre>  C_CONTIGUOUS : True\n  F_CONTIGUOUS : True\n  OWNDATA : True\n  WRITEABLE : True\n  ALIGNED : True\n  WRITEBACKIFCOPY : False</pre> In\u00a0[24]: Copied! <pre>arr_nan_inf = np.array([1, 2, np.nan, np.inf])\nnp.isnan(arr_nan_inf), np.isinf(arr_nan_inf), np.isfinite(arr_nan_inf)\n</pre> arr_nan_inf = np.array([1, 2, np.nan, np.inf]) np.isnan(arr_nan_inf), np.isinf(arr_nan_inf), np.isfinite(arr_nan_inf) Out[24]: <pre>(array([False, False,  True, False]),\n array([False, False, False,  True]),\n array([ True,  True, False, False]))</pre> In\u00a0[25]: Copied! <pre>arr_add = arr1 + 1  # Add 1 to each element\narr_add\n</pre> arr_add = arr1 + 1  # Add 1 to each element arr_add Out[25]: <pre>array([2, 3, 4])</pre> In\u00a0[26]: Copied! <pre>arr_mul = arr1 * 2  # Multiply each element by 2\narr_mul\n</pre> arr_mul = arr1 * 2  # Multiply each element by 2 arr_mul Out[26]: <pre>array([2, 4, 6])</pre> In\u00a0[27]: Copied! <pre>arr_sum = np.add(arr1, arr2)  # Add arrays element-wise\narr_sum\n</pre> arr_sum = np.add(arr1, arr2)  # Add arrays element-wise arr_sum Out[27]: <pre>array([2, 4, 6])</pre> In\u00a0[28]: Copied! <pre>arr_diff = np.subtract(arr1, arr2)  # Subtract arrays element-wise\narr_diff\n</pre> arr_diff = np.subtract(arr1, arr2)  # Subtract arrays element-wise arr_diff Out[28]: <pre>array([0, 0, 0])</pre> In\u00a0[29]: Copied! <pre>arr_sum_total = np.sum(arr1)  # Sum of all elements\narr_sum_total\n</pre> arr_sum_total = np.sum(arr1)  # Sum of all elements arr_sum_total Out[29]: <pre>6</pre> In\u00a0[30]: Copied! <pre>arr_mean = np.mean(arr1)  # Mean of elements\narr_mean\n</pre> arr_mean = np.mean(arr1)  # Mean of elements arr_mean Out[30]: <pre>2.0</pre> In\u00a0[31]: Copied! <pre>arr_max = np.max(arr1)  # Maximum value\narr_max\n</pre> arr_max = np.max(arr1)  # Maximum value arr_max Out[31]: <pre>3</pre> In\u00a0[32]: Copied! <pre>arr_min = np.min(arr1)  # Minimum value\narr_min\n</pre> arr_min = np.min(arr1)  # Minimum value arr_min Out[32]: <pre>1</pre> In\u00a0[33]: Copied! <pre>arr_prod = np.prod(arr1)  # Product of elements\narr_prod\n</pre> arr_prod = np.prod(arr1)  # Product of elements arr_prod Out[33]: <pre>6</pre> In\u00a0[34]: Copied! <pre>arr_cumsum = np.cumsum(arr1)  # Cumulative sum of elements\narr_cumsum\n</pre> arr_cumsum = np.cumsum(arr1)  # Cumulative sum of elements arr_cumsum Out[34]: <pre>array([1, 3, 6])</pre> In\u00a0[35]: Copied! <pre>arr_cumprod = np.cumprod(arr1)  # Cumulative product of elements\narr_cumprod\n</pre> arr_cumprod = np.cumprod(arr1)  # Cumulative product of elements arr_cumprod Out[35]: <pre>array([1, 2, 6])</pre> In\u00a0[36]: Copied! <pre>arr_exp = np.exp(arr1)  # Exponential of each element\narr_exp\n</pre> arr_exp = np.exp(arr1)  # Exponential of each element arr_exp Out[36]: <pre>array([ 2.71828183,  7.3890561 , 20.08553692])</pre> In\u00a0[37]: Copied! <pre>arr_log = np.log(arr1)  # Natural logarithm\narr_log\n</pre> arr_log = np.log(arr1)  # Natural logarithm arr_log Out[37]: <pre>array([0.        , 0.69314718, 1.09861229])</pre> In\u00a0[38]: Copied! <pre>arr_log10 = np.log10(arr1)  # Base-10 logarithm\narr_log10\n</pre> arr_log10 = np.log10(arr1)  # Base-10 logarithm arr_log10 Out[38]: <pre>array([0.        , 0.30103   , 0.47712125])</pre> In\u00a0[39]: Copied! <pre>arr_expm1 = np.expm1(arr1)  # Compute exp(x) - 1\narr_expm1\n</pre> arr_expm1 = np.expm1(arr1)  # Compute exp(x) - 1 arr_expm1 Out[39]: <pre>array([ 1.71828183,  6.3890561 , 19.08553692])</pre> In\u00a0[40]: Copied! <pre>arr_sin = np.sin(arr1)  # Sine of each element\narr_sin\n</pre> arr_sin = np.sin(arr1)  # Sine of each element arr_sin Out[40]: <pre>array([0.84147098, 0.90929743, 0.14112001])</pre> In\u00a0[41]: Copied! <pre>arr_cos = np.cos(arr1)  # Cosine of each element\narr_cos\n</pre> arr_cos = np.cos(arr1)  # Cosine of each element arr_cos Out[41]: <pre>array([ 0.54030231, -0.41614684, -0.9899925 ])</pre> In\u00a0[42]: Copied! <pre>arr_tan = np.tan(arr1)  # Tangent of each element\narr_tan\n</pre> arr_tan = np.tan(arr1)  # Tangent of each element arr_tan Out[42]: <pre>array([ 1.55740772, -2.18503986, -0.14254654])</pre> In\u00a0[43]: Copied! <pre>arr_arcsin = np.arcsin(arr1 / 10)  # Inverse sine\narr_arcsin\n</pre> arr_arcsin = np.arcsin(arr1 / 10)  # Inverse sine arr_arcsin Out[43]: <pre>array([0.10016742, 0.20135792, 0.30469265])</pre> In\u00a0[44]: Copied! <pre>arr_arccos = np.arccos(arr1 / 10)  # Inverse cosine\narr_arccos\n</pre> arr_arccos = np.arccos(arr1 / 10)  # Inverse cosine arr_arccos Out[44]: <pre>array([1.47062891, 1.36943841, 1.26610367])</pre> In\u00a0[45]: Copied! <pre>arr_arctan = np.arctan(arr1 / 10)  # Inverse tangent\narr_arctan\n</pre> arr_arctan = np.arctan(arr1 / 10)  # Inverse tangent arr_arctan Out[45]: <pre>array([0.09966865, 0.19739556, 0.29145679])</pre> In\u00a0[46]: Copied! <pre>arr_round = np.round(arr1_float, decimals=2)  # Round to 2 decimal places\narr_round\n</pre> arr_round = np.round(arr1_float, decimals=2)  # Round to 2 decimal places arr_round Out[46]: <pre>array([1., 2., 3.])</pre> In\u00a0[47]: Copied! <pre>arr_floor = np.floor(arr1_float)  # Floor operation\narr_floor\n</pre> arr_floor = np.floor(arr1_float)  # Floor operation arr_floor Out[47]: <pre>array([1., 2., 3.])</pre> In\u00a0[48]: Copied! <pre>arr_ceil = np.ceil(arr1_float)  # Ceiling operation\narr_ceil\n</pre> arr_ceil = np.ceil(arr1_float)  # Ceiling operation arr_ceil Out[48]: <pre>array([1., 2., 3.])</pre> In\u00a0[49]: Copied! <pre>arr_trunc = np.trunc(arr1_float)  # Truncate elements to integers\narr_trunc\n</pre> arr_trunc = np.trunc(arr1_float)  # Truncate elements to integers arr_trunc Out[49]: <pre>array([1., 2., 3.])</pre> In\u00a0[50]: Copied! <pre>arr_reshaped = arr1.reshape((3, 1))  # Reshape to 3x1 array\narr_reshaped\n</pre> arr_reshaped = arr1.reshape((3, 1))  # Reshape to 3x1 array arr_reshaped Out[50]: <pre>array([[1],\n       [2],\n       [3]])</pre> In\u00a0[51]: Copied! <pre>arr_flattened = arr1.flatten()  # Flatten the array to 1D\narr_flattened\n</pre> arr_flattened = arr1.flatten()  # Flatten the array to 1D arr_flattened Out[51]: <pre>array([1, 2, 3])</pre> In\u00a0[52]: Copied! <pre>arr_raveled = np.ravel(arr1)  # Return a flattened array\narr_raveled\n</pre> arr_raveled = np.ravel(arr1)  # Return a flattened array arr_raveled Out[52]: <pre>array([1, 2, 3])</pre> In\u00a0[53]: Copied! <pre>arr_T = arr1.reshape((1, 3)).T  # Transpose of the array\narr_T\n</pre> arr_T = arr1.reshape((1, 3)).T  # Transpose of the array arr_T Out[53]: <pre>array([[1],\n       [2],\n       [3]])</pre> In\u00a0[54]: Copied! <pre>arr_custom_T = np.transpose(arr1.reshape((3, 1)), (1, 0))  # Custom transpose\narr_custom_T\n</pre> arr_custom_T = np.transpose(arr1.reshape((3, 1)), (1, 0))  # Custom transpose arr_custom_T Out[54]: <pre>array([[1, 2, 3]])</pre> In\u00a0[55]: Copied! <pre>arr_concat = np.concatenate((arr1, arr2))  # Join arrays\narr_concat\n</pre> arr_concat = np.concatenate((arr1, arr2))  # Join arrays arr_concat Out[55]: <pre>array([1, 2, 3, 1, 2, 3])</pre> In\u00a0[56]: Copied! <pre>arr_hstack = np.hstack((arr1.reshape((3, 1)), arr2.reshape((3, 1))))  # Horizontal stack\narr_hstack\n</pre> arr_hstack = np.hstack((arr1.reshape((3, 1)), arr2.reshape((3, 1))))  # Horizontal stack arr_hstack Out[56]: <pre>array([[1, 1],\n       [2, 2],\n       [3, 3]])</pre> In\u00a0[57]: Copied! <pre>arr_vstack = np.vstack((arr1, arr2))  # Vertical stack\narr_vstack\n</pre> arr_vstack = np.vstack((arr1, arr2))  # Vertical stack arr_vstack Out[57]: <pre>array([[1, 2, 3],\n       [1, 2, 3]])</pre> In\u00a0[58]: Copied! <pre>arr_split = np.split(arr_concat, 3)  # Split into 3 equal parts\narr_split\n</pre> arr_split = np.split(arr_concat, 3)  # Split into 3 equal parts arr_split Out[58]: <pre>[array([1, 2]), array([3, 1]), array([2, 3])]</pre> In\u00a0[59]: Copied! <pre>arr_hsplit = np.hsplit(arr_hstack, 2)  # Split horizontally\narr_hsplit\n</pre> arr_hsplit = np.hsplit(arr_hstack, 2)  # Split horizontally arr_hsplit Out[59]: <pre>[array([[1],\n        [2],\n        [3]]),\n array([[1],\n        [2],\n        [3]])]</pre> In\u00a0[60]: Copied! <pre>arr_vsplit = np.vsplit(arr_vstack, 2)  # Split vertically\narr_vsplit\n</pre> arr_vsplit = np.vsplit(arr_vstack, 2)  # Split vertically arr_vsplit Out[60]: <pre>[array([[1, 2, 3]]), array([[1, 2, 3]])]</pre> In\u00a0[61]: Copied! <pre>arr_expanded = np.expand_dims(arr1, axis=0)  # Expand dimensions\narr_expanded\n</pre> arr_expanded = np.expand_dims(arr1, axis=0)  # Expand dimensions arr_expanded Out[61]: <pre>array([[1, 2, 3]])</pre> In\u00a0[62]: Copied! <pre>arr_squeezed = np.squeeze(arr_expanded)  # Remove single-dimensional entries\narr_squeezed\n</pre> arr_squeezed = np.squeeze(arr_expanded)  # Remove single-dimensional entries arr_squeezed Out[62]: <pre>array([1, 2, 3])</pre> In\u00a0[63]: Copied! <pre>arr_tiled = np.tile(arr1, (2, 3))  # Repeat array\narr_tiled\n</pre> arr_tiled = np.tile(arr1, (2, 3))  # Repeat array arr_tiled Out[63]: <pre>array([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n       [1, 2, 3, 1, 2, 3, 1, 2, 3]])</pre> In\u00a0[64]: Copied! <pre>arr_repeated = np.repeat(arr1, 3)  # Repeat elements of an array\narr_repeated\n</pre> arr_repeated = np.repeat(arr1, 3)  # Repeat elements of an array arr_repeated Out[64]: <pre>array([1, 1, 1, 2, 2, 2, 3, 3, 3])</pre> In\u00a0[65]: Copied! <pre>arr_rot90 = np.rot90(arr1.reshape((3, 1)))  # Rotate array by 90 degrees\narr_rot90\n</pre> arr_rot90 = np.rot90(arr1.reshape((3, 1)))  # Rotate array by 90 degrees arr_rot90 Out[65]: <pre>array([[1, 2, 3]])</pre> In\u00a0[66]: Copied! <pre>arr_fliplr = np.fliplr(arr1.reshape((3, 1)))  # Flip array left to right\narr_fliplr\n</pre> arr_fliplr = np.fliplr(arr1.reshape((3, 1)))  # Flip array left to right arr_fliplr Out[66]: <pre>array([[1],\n       [2],\n       [3]])</pre> In\u00a0[67]: Copied! <pre>arr_flipud = np.flipud(arr1.reshape((3, 1)))  # Flip array upside down\narr_flipud\n</pre> arr_flipud = np.flipud(arr1.reshape((3, 1)))  # Flip array upside down arr_flipud Out[67]: <pre>array([[3],\n       [2],\n       [1]])</pre> In\u00a0[68]: Copied! <pre>arr_dot = np.dot(arr1, arr2)  # Dot product\narr_dot\n</pre> arr_dot = np.dot(arr1, arr2)  # Dot product arr_dot Out[68]: <pre>14</pre> In\u00a0[69]: Copied! <pre>arr_matmul = np.matmul(arr1.reshape((3, 1)), arr2.reshape((1, 3)))  # Matrix multiplication\narr_matmul\n</pre> arr_matmul = np.matmul(arr1.reshape((3, 1)), arr2.reshape((1, 3)))  # Matrix multiplication arr_matmul Out[69]: <pre>array([[1, 2, 3],\n       [2, 4, 6],\n       [3, 6, 9]])</pre> In\u00a0[70]: Copied! <pre>arr_matmul_op = arr1.reshape((3, 1)) @ arr2.reshape((1, 3))  # Matrix multiplication using @\narr_matmul_op\n</pre> arr_matmul_op = arr1.reshape((3, 1)) @ arr2.reshape((1, 3))  # Matrix multiplication using @ arr_matmul_op Out[70]: <pre>array([[1, 2, 3],\n       [2, 4, 6],\n       [3, 6, 9]])</pre> In\u00a0[71]: Copied! <pre>A = np.array([[3, 1], [1, 2]])\nb = np.array([9, 8])\nx = np.linalg.solve(A, b)  # Solve linear equations Ax = b\nx\n</pre> A = np.array([[3, 1], [1, 2]]) b = np.array([9, 8]) x = np.linalg.solve(A, b)  # Solve linear equations Ax = b x Out[71]: <pre>array([2., 3.])</pre> In\u00a0[72]: Copied! <pre>arr_eigvals, arr_eigvecs = np.linalg.eig(A)  # Eigenvalues and eigenvectors\narr_eigvals, arr_eigvecs\n</pre> arr_eigvals, arr_eigvecs = np.linalg.eig(A)  # Eigenvalues and eigenvectors arr_eigvals, arr_eigvecs Out[72]: <pre>(array([3.61803399, 1.38196601]),\n array([[ 0.85065081, -0.52573111],\n        [ 0.52573111,  0.85065081]]))</pre> In\u00a0[73]: Copied! <pre>arr_inv = np.linalg.inv(A)  # Inverse of a matrix\narr_inv\n</pre> arr_inv = np.linalg.inv(A)  # Inverse of a matrix arr_inv Out[73]: <pre>array([[ 0.4, -0.2],\n       [-0.2,  0.6]])</pre> In\u00a0[74]: Copied! <pre>arr_det = np.linalg.det(A)  # Determinant of a matrix\narr_det\n</pre> arr_det = np.linalg.det(A)  # Determinant of a matrix arr_det Out[74]: <pre>5.000000000000001</pre> In\u00a0[75]: Copied! <pre>U, S, V = np.linalg.svd(A)  # Singular Value Decomposition\nU, S, V\n</pre> U, S, V = np.linalg.svd(A)  # Singular Value Decomposition U, S, V Out[75]: <pre>(array([[-0.85065081, -0.52573111],\n        [-0.52573111,  0.85065081]]),\n array([3.61803399, 1.38196601]),\n array([[-0.85065081, -0.52573111],\n        [-0.52573111,  0.85065081]]))</pre> In\u00a0[76]: Copied! <pre>arr_norm = np.linalg.norm(arr1)  # Compute matrix or vector norm\narr_norm\n</pre> arr_norm = np.linalg.norm(arr1)  # Compute matrix or vector norm arr_norm Out[76]: <pre>3.7416573867739413</pre> In\u00a0[77]: Copied! <pre>arr_cond = np.linalg.cond(A)  # Compute the condition number of a matrix\narr_cond\n</pre> arr_cond = np.linalg.cond(A)  # Compute the condition number of a matrix arr_cond Out[77]: <pre>2.618033988749896</pre> In\u00a0[78]: Copied! <pre>arr_mean = np.mean(arr1)  # Mean\narr_mean\n</pre> arr_mean = np.mean(arr1)  # Mean arr_mean Out[78]: <pre>2.0</pre> In\u00a0[79]: Copied! <pre>arr_median = np.median(arr1)  # Median\narr_median\n</pre> arr_median = np.median(arr1)  # Median arr_median Out[79]: <pre>2.0</pre> In\u00a0[80]: Copied! <pre>arr_var = np.var(arr1)  # Variance\narr_var\n</pre> arr_var = np.var(arr1)  # Variance arr_var Out[80]: <pre>0.6666666666666666</pre> In\u00a0[81]: Copied! <pre>arr_std = np.std(arr1)  # Standard deviation\narr_std\n</pre> arr_std = np.std(arr1)  # Standard deviation arr_std Out[81]: <pre>0.816496580927726</pre> In\u00a0[82]: Copied! <pre>arr_percentile = np.percentile(arr1, 50)  # 50th percentile (median)\narr_percentile\n</pre> arr_percentile = np.percentile(arr1, 50)  # 50th percentile (median) arr_percentile Out[82]: <pre>2.0</pre> In\u00a0[83]: Copied! <pre>arr_corr = np.corrcoef(arr1, arr2)  # Correlation coefficient\narr_corr\n</pre> arr_corr = np.corrcoef(arr1, arr2)  # Correlation coefficient arr_corr Out[83]: <pre>array([[1., 1.],\n       [1., 1.]])</pre> In\u00a0[84]: Copied! <pre>arr_cov = np.cov(arr1, arr2)  # Covariance\narr_cov\n</pre> arr_cov = np.cov(arr1, arr2)  # Covariance arr_cov Out[84]: <pre>array([[1., 1.],\n       [1., 1.]])</pre> In\u00a0[85]: Copied! <pre>arr_hist, arr_bins = np.histogram(arr1, bins=3)  # Histogram of an array\narr_hist, arr_bins\n</pre> arr_hist, arr_bins = np.histogram(arr1, bins=3)  # Histogram of an array arr_hist, arr_bins Out[85]: <pre>(array([1, 1, 1]), array([1.        , 1.66666667, 2.33333333, 3.        ]))</pre> In\u00a0[86]: Copied! <pre>from scipy import stats\narr_binned_statistic = stats.binned_statistic(arr1, arr1, statistic='mean', bins=3)  # Compute binned statistics\narr_binned_statistic.statistic\n</pre> from scipy import stats arr_binned_statistic = stats.binned_statistic(arr1, arr1, statistic='mean', bins=3)  # Compute binned statistics arr_binned_statistic.statistic Out[86]: <pre>array([1., 2., 3.])</pre> In\u00a0[87]: Copied! <pre>arr_broadcast_add = arr1 + 5  # Add 5 to all elements\narr_broadcast_add\n</pre> arr_broadcast_add = arr1 + 5  # Add 5 to all elements arr_broadcast_add Out[87]: <pre>array([6, 7, 8])</pre> In\u00a0[88]: Copied! <pre>arr_broadcast_array = arr1 + np.array([1, 2, 3])  # Add array [1, 2, 3] to each row\narr_broadcast_array\n</pre> arr_broadcast_array = arr1 + np.array([1, 2, 3])  # Add array [1, 2, 3] to each row arr_broadcast_array Out[88]: <pre>array([2, 4, 6])</pre> In\u00a0[89]: Copied! <pre>arr_broadcast_mult = arr1 * np.array([1, 2, 3])  # Element-wise multiplication with broadcasting\narr_broadcast_mult\n</pre> arr_broadcast_mult = arr1 * np.array([1, 2, 3])  # Element-wise multiplication with broadcasting arr_broadcast_mult Out[89]: <pre>array([1, 4, 9])</pre> In\u00a0[90]: Copied! <pre>arr_broadcast_expand = np.expand_dims(arr1, axis=0) + arr1  # Broadcasting with dimension expansion\narr_broadcast_expand\n</pre> arr_broadcast_expand = np.expand_dims(arr1, axis=0) + arr1  # Broadcasting with dimension expansion arr_broadcast_expand Out[90]: <pre>array([[2, 4, 6]])</pre> In\u00a0[91]: Copied! <pre>first_element = arr1[0]  # First element\nfirst_element\n</pre> first_element = arr1[0]  # First element first_element Out[91]: <pre>1</pre> In\u00a0[92]: Copied! <pre>last_element = arr1[-1]  # Last element\nlast_element\n</pre> last_element = arr1[-1]  # Last element last_element Out[92]: <pre>3</pre> In\u00a0[93]: Copied! <pre>element_0_2 = arr1[0]  # First element\nthird_element = arr1[2]  # Third element\nfirst_element, third_element\n</pre> element_0_2 = arr1[0]  # First element third_element = arr1[2]  # Third element first_element, third_element Out[93]: <pre>(1, 3)</pre> In\u00a0[94]: Copied! <pre>arr_slice_1_3 = arr1[1:3]  # Elements from index 1 to 2\narr_slice_1_3\n</pre> arr_slice_1_3 = arr1[1:3]  # Elements from index 1 to 2 arr_slice_1_3 Out[94]: <pre>array([2, 3])</pre> In\u00a0[95]: Copied! <pre>arr_slice_all = arr1[:]  # All elements\narr_slice_all\n</pre> arr_slice_all = arr1[:]  # All elements arr_slice_all Out[95]: <pre>array([1, 2, 3])</pre> In\u00a0[96]: Copied! <pre>arr_slice_skip = arr1[::2]  # Every other element\narr_slice_skip\n</pre> arr_slice_skip = arr1[::2]  # Every other element arr_slice_skip Out[96]: <pre>array([1, 3])</pre> In\u00a0[97]: Copied! <pre>arr_fancy_index = arr1[[0, 2]]  # Elements 0 and 2\narr_fancy_index\n</pre> arr_fancy_index = arr1[[0, 2]]  # Elements 0 and 2 arr_fancy_index Out[97]: <pre>array([1, 3])</pre> In\u00a0[98]: Copied! <pre>arr_bool_mask = arr1[arr1 &gt; 2]  # Elements greater than 2\narr_bool_mask\n</pre> arr_bool_mask = arr1[arr1 &gt; 2]  # Elements greater than 2 arr_bool_mask Out[98]: <pre>array([3])</pre> In\u00a0[99]: Copied! <pre>arr_where = np.where(arr1 &gt; 2, arr1, -arr1)  # Replace negative values with their absolute value\narr_where\n</pre> arr_where = np.where(arr1 &gt; 2, arr1, -arr1)  # Replace negative values with their absolute value arr_where Out[99]: <pre>array([-1, -2,  3])</pre> In\u00a0[100]: Copied! <pre>arr_set_values = arr1.copy()\narr_set_values[arr_set_values &gt; 2] = 0  # Set all positive elements to 0\narr_set_values\n</pre> arr_set_values = arr1.copy() arr_set_values[arr_set_values &gt; 2] = 0  # Set all positive elements to 0 arr_set_values Out[100]: <pre>array([1, 2, 0])</pre> In\u00a0[101]: Copied! <pre>arr_ix = np.ix_([0, 1], [2, 3])  # Create a mesh grid from indexing arrays\narr_ix\n</pre> arr_ix = np.ix_([0, 1], [2, 3])  # Create a mesh grid from indexing arrays arr_ix Out[101]: <pre>(array([[0],\n        [1]]),\n array([[2, 3]]))</pre> In\u00a0[102]: Copied! <pre>arr_rand = np.random.rand(2, 3)  # Uniform distribution (0, 1)\narr_rand\n</pre> arr_rand = np.random.rand(2, 3)  # Uniform distribution (0, 1) arr_rand Out[102]: <pre>array([[0.67485015, 0.42229856, 0.98348739],\n       [0.01204425, 0.90966669, 0.70587384]])</pre> In\u00a0[103]: Copied! <pre>arr_randn = np.random.randn(2, 3)  # Standard normal distribution\narr_randn\n</pre> arr_randn = np.random.randn(2, 3)  # Standard normal distribution arr_randn Out[103]: <pre>array([[ 0.74664931, -0.14473226,  0.11518257],\n       [-1.03882137,  1.94984805,  1.95339008]])</pre> In\u00a0[104]: Copied! <pre>arr_randint = np.random.randint(0, 10, size=(2, 3))  # Random integers between 0 and 9\narr_randint\n</pre> arr_randint = np.random.randint(0, 10, size=(2, 3))  # Random integers between 0 and 9 arr_randint Out[104]: <pre>array([[4, 7, 8],\n       [9, 8, 8]])</pre> In\u00a0[105]: Copied! <pre>arr_perm = np.random.permutation(arr1)  # Randomly permute an array\narr_perm\n</pre> arr_perm = np.random.permutation(arr1)  # Randomly permute an array arr_perm Out[105]: <pre>array([2, 3, 1])</pre> In\u00a0[106]: Copied! <pre>arr_choice = np.random.choice(arr1, size=3, replace=False)  # Random sample without replacement\narr_choice\n</pre> arr_choice = np.random.choice(arr1, size=3, replace=False)  # Random sample without replacement arr_choice Out[106]: <pre>array([2, 3, 1])</pre> In\u00a0[107]: Copied! <pre>arr_binomial = np.random.binomial(n=10, p=0.5, size=10)  # Binomial distribution\narr_binomial\n</pre> arr_binomial = np.random.binomial(n=10, p=0.5, size=10)  # Binomial distribution arr_binomial Out[107]: <pre>array([4, 4, 1, 5, 6, 7, 3, 7, 6, 7])</pre> In\u00a0[108]: Copied! <pre>arr_poisson = np.random.poisson(lam=3, size=10)  # Poisson distribution\narr_poisson\n</pre> arr_poisson = np.random.poisson(lam=3, size=10)  # Poisson distribution arr_poisson Out[108]: <pre>array([2, 6, 2, 3, 1, 1, 2, 3, 2, 5])</pre> In\u00a0[109]: Copied! <pre>np.random.seed(42)  # Set random seed for reproducibility\narr_rand_seed = np.random.rand(2, 3)\narr_rand_seed\n</pre> np.random.seed(42)  # Set random seed for reproducibility arr_rand_seed = np.random.rand(2, 3) arr_rand_seed Out[109]: <pre>array([[0.37454012, 0.95071431, 0.73199394],\n       [0.59865848, 0.15601864, 0.15599452]])</pre> In\u00a0[110]: Copied! <pre>np.save('array.npy', arr1)  # Save array to binary file\narr_loaded = np.load('array.npy')  # Load array from binary file\narr_loaded\n</pre> np.save('array.npy', arr1)  # Save array to binary file arr_loaded = np.load('array.npy')  # Load array from binary file arr_loaded Out[110]: <pre>array([1, 2, 3])</pre> In\u00a0[111]: Copied! <pre>np.savetxt('array.txt', arr1)  # Save array to text file\narr_loaded_txt = np.loadtxt('array.txt')  # Load array from text file\narr_loaded_txt\n</pre> np.savetxt('array.txt', arr1)  # Save array to text file arr_loaded_txt = np.loadtxt('array.txt')  # Load array from text file arr_loaded_txt Out[111]: <pre>array([1., 2., 3.])</pre> In\u00a0[112]: Copied! <pre>np.savez('arrays.npz', arr1=arr1, arr2=arr2)  # Save multiple arrays to a compressed file\nnpzfile = np.load('arrays.npz')\nnpzfile['arr1'], npzfile['arr2']\n</pre> np.savez('arrays.npz', arr1=arr1, arr2=arr2)  # Save multiple arrays to a compressed file npzfile = np.load('arrays.npz') npzfile['arr1'], npzfile['arr2'] Out[112]: <pre>(array([1, 2, 3]), array([1, 2, 3]))</pre> In\u00a0[113]: Copied! <pre>arr1\n</pre> arr1 Out[113]: <pre>array([1, 2, 3])</pre> In\u00a0[114]: Copied! <pre>np.savetxt('data.csv', arr1, delimiter=',')  # Save data to CSV file\n</pre> np.savetxt('data.csv', arr1, delimiter=',')  # Save data to CSV file In\u00a0[115]: Copied! <pre>arr_csv = np.genfromtxt('data.csv', delimiter=',')  # Load data from CSV file\narr_csv\n</pre> arr_csv = np.genfromtxt('data.csv', delimiter=',')  # Load data from CSV file arr_csv Out[115]: <pre>array([1., 2., 3.])</pre> In\u00a0[116]: Copied! <pre>p = np.poly1d([1, 2, 3])  # Define a polynomial p(x) = 1x^2 + 2x + 3\np(2)  # Evaluate polynomial at x = 2\n</pre> p = np.poly1d([1, 2, 3])  # Define a polynomial p(x) = 1x^2 + 2x + 3 p(2)  # Evaluate polynomial at x = 2 Out[116]: <pre>11</pre> In\u00a0[117]: Copied! <pre>p.roots  # Find roots of the polynomial\n</pre> p.roots  # Find roots of the polynomial Out[117]: <pre>array([-1.+1.41421356j, -1.-1.41421356j])</pre> In\u00a0[118]: Copied! <pre>x = np.array([1, 2, 3, 4])\ny = np.array([1, 4, 9, 16])\np_fit = np.polyfit(x, y, deg=2)  # Fit a polynomial of degree 2 to data points (x, y)\np_fit\n</pre> x = np.array([1, 2, 3, 4]) y = np.array([1, 4, 9, 16]) p_fit = np.polyfit(x, y, deg=2)  # Fit a polynomial of degree 2 to data points (x, y) p_fit Out[118]: <pre>array([ 1.00000000e+00, -6.00566855e-15,  9.41435428e-15])</pre> In\u00a0[119]: Copied! <pre>p_deriv = p.deriv()  # Derivative of the polynomial\np_deriv\n</pre> p_deriv = p.deriv()  # Derivative of the polynomial p_deriv Out[119]: <pre>poly1d([2, 2])</pre> In\u00a0[120]: Copied! <pre>p_integ = p.integ()  # Integral of the polynomial\np_integ\n</pre> p_integ = p.integ()  # Integral of the polynomial p_integ Out[120]: <pre>poly1d([0.33333333, 1.        , 3.        , 0.        ])</pre> In\u00a0[121]: Copied! <pre>def add_five(x):\n    return x + 5\n\nvectorized_func = np.vectorize(add_five)  # Apply a function element-wise to an array\nvectorized_func(arr1)\n</pre> def add_five(x):     return x + 5  vectorized_func = np.vectorize(add_five)  # Apply a function element-wise to an array vectorized_func(arr1) Out[121]: <pre>array([6, 7, 8])</pre> In\u00a0[122]: Copied! <pre>x = np.array([1, 2, 3])\ny = np.array([4, 5, 6])\nX, Y = np.meshgrid(x, y)  # Create a coordinate grid from 1D arrays x and y\nX, Y\n</pre> x = np.array([1, 2, 3]) y = np.array([4, 5, 6]) X, Y = np.meshgrid(x, y)  # Create a coordinate grid from 1D arrays x and y X, Y Out[122]: <pre>(array([[1, 2, 3],\n        [1, 2, 3],\n        [1, 2, 3]]),\n array([[4, 4, 4],\n        [5, 5, 5],\n        [6, 6, 6]]))</pre> In\u00a0[123]: Copied! <pre>arr_add_at = np.array([1, 2, 3])\nnp.add.at(arr_add_at, [0, 1], 5)  # Increment elements at indices `idx` by 5\narr_add_at\n</pre> arr_add_at = np.array([1, 2, 3]) np.add.at(arr_add_at, [0, 1], 5)  # Increment elements at indices `idx` by 5 arr_add_at Out[123]: <pre>array([6, 7, 3])</pre> In\u00a0[124]: Copied! <pre>arr_sorted = np.sort(arr1)  # Sort array\narr_sorted\n</pre> arr_sorted = np.sort(arr1)  # Sort array arr_sorted Out[124]: <pre>array([1, 2, 3])</pre> In\u00a0[125]: Copied! <pre>arr_argsort = np.argsort(arr1)  # Indices of the sorted array\narr_argsort\n</pre> arr_argsort = np.argsort(arr1)  # Indices of the sorted array arr_argsort Out[125]: <pre>array([0, 1, 2])</pre> In\u00a0[126]: Copied! <pre>arr_where_condition = np.where(arr1 &gt; 2)  # Indices where the condition is met\narr_where_condition\n</pre> arr_where_condition = np.where(arr1 &gt; 2)  # Indices where the condition is met arr_where_condition Out[126]: <pre>(array([2]),)</pre> In\u00a0[127]: Copied! <pre>arr_count_nonzero = np.count_nonzero(arr1)  # Count non-zero elements\narr_count_nonzero\n</pre> arr_count_nonzero = np.count_nonzero(arr1)  # Count non-zero elements arr_count_nonzero Out[127]: <pre>3</pre> In\u00a0[128]: Copied! <pre>arr_flags = arr1.flags  # Check memory layout (C_CONTIGUOUS, F_CONTIGUOUS)\narr_flags\n</pre> arr_flags = arr1.flags  # Check memory layout (C_CONTIGUOUS, F_CONTIGUOUS) arr_flags Out[128]: <pre>  C_CONTIGUOUS : True\n  F_CONTIGUOUS : True\n  OWNDATA : True\n  WRITEABLE : True\n  ALIGNED : True\n  WRITEBACKIFCOPY : False</pre> In\u00a0[129]: Copied! <pre>arr_contig = np.ascontiguousarray(arr1)  # Convert to C-contiguous array\narr_contig.flags\n</pre> arr_contig = np.ascontiguousarray(arr1)  # Convert to C-contiguous array arr_contig.flags Out[129]: <pre>  C_CONTIGUOUS : True\n  F_CONTIGUOUS : True\n  OWNDATA : True\n  WRITEABLE : True\n  ALIGNED : True\n  WRITEBACKIFCOPY : False</pre> In\u00a0[130]: Copied! <pre>memmap_arr = np.memmap('data.dat', dtype='float32', mode='w+', shape=(3, 3))  # Memory-mapped file\nmemmap_arr\n</pre> memmap_arr = np.memmap('data.dat', dtype='float32', mode='w+', shape=(3, 3))  # Memory-mapped file memmap_arr Out[130]: <pre>memmap([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]], dtype=float32)</pre> In\u00a0[131]: Copied! <pre>arr_copy = arr1.copy()  # Create a deep copy of the array\narr_copy\n</pre> arr_copy = arr1.copy()  # Create a deep copy of the array arr_copy Out[131]: <pre>array([1, 2, 3])</pre> In\u00a0[132]: Copied! <pre>arr_view = arr1.view()  # Create a view of the array (shallow copy)\narr_view\n</pre> arr_view = arr1.view()  # Create a view of the array (shallow copy) arr_view Out[132]: <pre>array([1, 2, 3])</pre> In\u00a0[133]: Copied! <pre>arr_take = np.take(arr1, [0, 2])  # Take elements at indices 0 and 2\narr_take\n</pre> arr_take = np.take(arr1, [0, 2])  # Take elements at indices 0 and 2 arr_take Out[133]: <pre>array([1, 3])</pre> In\u00a0[134]: Copied! <pre>arr_put = arr1.copy()\nnp.put(arr_put, [0, 2], [-1, -2])  # Set elements at indices 0 and 2\narr_put\n</pre> arr_put = arr1.copy() np.put(arr_put, [0, 2], [-1, -2])  # Set elements at indices 0 and 2 arr_put Out[134]: <pre>array([-1,  2, -2])</pre> In\u00a0[135]: Copied! <pre>arr_choose = np.choose([0, 1], arr1)  # Construct an array from elements chosen from `arr1`\narr_choose\n</pre> arr_choose = np.choose([0, 1], arr1)  # Construct an array from elements chosen from `arr1` arr_choose Out[135]: <pre>array([1, 2])</pre> In\u00a0[136]: Copied! <pre>arr_lexsort = np.lexsort((arr2, arr1))  # Sort by `arr1`, then by `arr2`\narr_lexsort\n</pre> arr_lexsort = np.lexsort((arr2, arr1))  # Sort by `arr1`, then by `arr2` arr_lexsort Out[136]: <pre>array([0, 1, 2])</pre> In\u00a0[137]: Copied! <pre>arr_determinant = np.linalg.det(A)  # Determinant of a matrix\narr_determinant\n</pre> arr_determinant = np.linalg.det(A)  # Determinant of a matrix arr_determinant Out[137]: <pre>5.000000000000001</pre> In\u00a0[138]: Copied! <pre>arr_rank = np.linalg.matrix_rank(A)  # Rank of a matrix\narr_rank\n</pre> arr_rank = np.linalg.matrix_rank(A)  # Rank of a matrix arr_rank Out[138]: <pre>2</pre> In\u00a0[139]: Copied! <pre>arr_trace = np.trace(A)  # Sum of diagonal elements (trace)\narr_trace\n</pre> arr_trace = np.trace(A)  # Sum of diagonal elements (trace) arr_trace Out[139]: <pre>5</pre> In\u00a0[140]: Copied! <pre>arr_kron = np.kron(arr1, arr2)  # Kronecker product of two arrays\narr_kron\n</pre> arr_kron = np.kron(arr1, arr2)  # Kronecker product of two arrays arr_kron Out[140]: <pre>array([1, 2, 3, 2, 4, 6, 3, 6, 9])</pre> In\u00a0[141]: Copied! <pre>arr_outer = np.outer(arr1, arr2)  # Outer product of two arrays\narr_outer\n</pre> arr_outer = np.outer(arr1, arr2)  # Outer product of two arrays arr_outer Out[141]: <pre>array([[1, 2, 3],\n       [2, 4, 6],\n       [3, 6, 9]])</pre> In\u00a0[142]: Copied! <pre>arr_solve = np.linalg.solve(A, b)  # Solve Ax = b for x\narr_solve\n</pre> arr_solve = np.linalg.solve(A, b)  # Solve Ax = b for x arr_solve Out[142]: <pre>array([2., 3.])</pre> In\u00a0[143]: Copied! <pre>arr_lstsq = np.linalg.lstsq(A, b, rcond=None)  # Solve Ax = b using least squares\narr_lstsq[0]\n</pre> arr_lstsq = np.linalg.lstsq(A, b, rcond=None)  # Solve Ax = b using least squares arr_lstsq[0] Out[143]: <pre>array([2., 3.])</pre> In\u00a0[144]: Copied! <pre>arr_dtype = np.array([1, 2, 3], dtype=np.float32)  # Specify data type\narr_dtype\n</pre> arr_dtype = np.array([1, 2, 3], dtype=np.float32)  # Specify data type arr_dtype Out[144]: <pre>array([1., 2., 3.], dtype=float32)</pre> In\u00a0[145]: Copied! <pre>arr_converted_dtype = arr1.astype(np.int32)  # Convert array to specified data type\narr_converted_dtype\n</pre> arr_converted_dtype = arr1.astype(np.int32)  # Convert array to specified data type arr_converted_dtype Out[145]: <pre>array([1, 2, 3], dtype=int32)</pre> In\u00a0[146]: Copied! <pre>arr_complex = np.array([1+2j, 3+4j], dtype=np.complex64)  # Complex data type\narr_complex\n</pre> arr_complex = np.array([1+2j, 3+4j], dtype=np.complex64)  # Complex data type arr_complex Out[146]: <pre>array([1.+2.j, 3.+4.j], dtype=complex64)</pre> In\u00a0[147]: Copied! <pre>arr_dtype_check = arr_complex.dtype  # Check data type\narr_dtype_check\n</pre> arr_dtype_check = arr_complex.dtype  # Check data type arr_dtype_check Out[147]: <pre>dtype('complex64')</pre> In\u00a0[148]: Copied! <pre>np.issubdtype(arr_complex.dtype, np.number)  # Check if the data type is a subtype of `np.number`\n</pre> np.issubdtype(arr_complex.dtype, np.number)  # Check if the data type is a subtype of `np.number` Out[148]: <pre>True</pre>"},{"location":"Cheat-Sheets/NumPy/#numpy","title":"NumPy\u00b6","text":"<p>NumPy, which stands for Numerical Python, is a free, open-source Python library for working with arrays. It's one of the most popular packages for scientific computing in Python, and is used for data manipulation and analysis, including data cleaning, transformation, and aggregation.</p> <ul> <li>Official Website: https://numpy.org/</li> <li>Installation:  (https://numpy.org/install/)<pre>pip install numpy\n</pre> </li> <li>Documentation: https://numpy.org/doc</li> <li>GitHub: https://github.com/numpy/numpy</li> </ul>"},{"location":"Cheat-Sheets/NumPy/#basics","title":"Basics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-creation","title":"Array Creation\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#from-lists-tuples-and-buffers","title":"From Lists, Tuples, and Buffers\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#zeros-ones-and-empty-arrays","title":"Zeros, Ones, and Empty Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#ranges-and-random-numbers","title":"Ranges and Random Numbers\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#identity-and-diagonal-matrices","title":"Identity and Diagonal Matrices\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#structured-arrays","title":"Structured Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#using-npfull-and-nptile","title":"Using <code>np.full</code> and <code>np.tile</code>\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-inspection","title":"Array Inspection\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#shape-and-size","title":"Shape and Size\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#data-type","title":"Data Type\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#memory-layout","title":"Memory Layout\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#checking-for-nan-and-inf-values","title":"Checking for <code>NaN</code> and <code>Inf</code> Values\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-mathematics","title":"Array Mathematics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#basic-operations","title":"Basic Operations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#aggregate-functions","title":"Aggregate Functions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#exponentials-and-logarithms","title":"Exponentials and Logarithms\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#trigonometric-functions","title":"Trigonometric Functions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#rounding-and-precision-control","title":"Rounding and Precision Control\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-manipulation","title":"Array Manipulation\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#reshaping","title":"Reshaping\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#transposing","title":"Transposing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#joining-and-splitting-arrays","title":"Joining and Splitting Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#changing-dimensions","title":"Changing Dimensions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-repetition","title":"Array Repetition\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#rotating-and-flipping-arrays","title":"Rotating and Flipping Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#linear-algebra","title":"Linear Algebra\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#dot-product-and-matrix-multiplication","title":"Dot Product and Matrix Multiplication\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#solving-linear-equations","title":"Solving Linear Equations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#eigenvalues-and-eigenvectors","title":"Eigenvalues and Eigenvectors\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#inverse-and-determinant","title":"Inverse and Determinant\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#singular-value-decomposition-svd","title":"Singular Value Decomposition (SVD)\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#norms-and-condition-numbers","title":"Norms and Condition Numbers\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#statistics","title":"Statistics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#descriptive-statistics","title":"Descriptive Statistics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#percentiles","title":"Percentiles\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#correlation-and-covariance","title":"Correlation and Covariance\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#histogram","title":"Histogram\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#binned-statistics","title":"Binned Statistics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#broadcasting","title":"Broadcasting\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#basic-broadcasting","title":"Basic Broadcasting\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-broadcasting","title":"Advanced Broadcasting\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#indexing-and-slicing","title":"Indexing and Slicing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#basic-indexing","title":"Basic Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#slicing","title":"Slicing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#fancy-indexing","title":"Fancy Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#boolean-masking-and-advanced-indexing","title":"Boolean Masking and Advanced Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#boolean-masking","title":"Boolean Masking\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-indexing-with-conditions","title":"Advanced Indexing with Conditions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#setting-values","title":"Setting Values\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-indexing-with-npix_","title":"Advanced Indexing with np.ix_\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#random","title":"Random\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#random-numbers","title":"Random Numbers\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#random-permutations","title":"Random Permutations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#sampling-and-distributions","title":"Sampling and Distributions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#setting-seed","title":"Setting Seed\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#io-with-numpy","title":"I/O with NumPy\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#reading-and-writing-files","title":"Reading and Writing Files\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#saving-and-loading-multiple-arrays","title":"Saving and Loading Multiple Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#reading-and-writing-csv-files","title":"Reading and Writing CSV Files\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#polynomials","title":"Polynomials\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#polynomial-operations","title":"Polynomial Operations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#polynomial-fitting","title":"Polynomial Fitting\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#polynomial-derivatives-and-integrals","title":"Polynomial Derivatives and Integrals\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-array-operations","title":"Advanced Array Operations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#vectorize-functions","title":"Vectorize Functions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#meshgrid","title":"Meshgrid\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#broadcasting-with-advanced-indexing","title":"Broadcasting with Advanced Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#sorting-arrays","title":"Sorting Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#searching-and-counting-elements","title":"Searching and Counting Elements\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#memory-management","title":"Memory Management\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#memory-layout-and-optimization","title":"Memory Layout and Optimization\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#memory-mapping-files","title":"Memory Mapping Files\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#copying-and-views","title":"Copying and Views\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-indexing","title":"Advanced Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#using-nptake-and-npput","title":"Using <code>np.take</code> and <code>np.put</code>\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#using-npchoose","title":"Using <code>np.choose</code>\u00b6","text":"<p><code>np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])</code></p>"},{"location":"Cheat-Sheets/NumPy/#using-nplexsort","title":"Using <code>np.lexsort</code>\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#matrix-operations","title":"Matrix Operations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#determinant-rank-and-trace","title":"Determinant, Rank, and Trace\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#kronecker-product-and-outer-product","title":"Kronecker Product and Outer Product\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#solving-systems-of-linear-equations","title":"Solving Systems of Linear Equations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#data-types","title":"Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#specifying-data-types","title":"Specifying Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#converting-data-types","title":"Converting Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#complex-data-types","title":"Complex Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#checking-data-types","title":"Checking Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy_/","title":"NumPy","text":"<ul> <li>NumPy<ul> <li>Array Creation<ul> <li>From Lists, Tuples, and Buffers</li> <li>Zeros, Ones, and Empty Arrays</li> <li>Ranges and Random Numbers</li> <li>Identity and Diagonal Matrices</li> <li>Structured Arrays</li> <li>Using np.full and np.tile</li> </ul> </li> <li>Array Inspection<ul> <li>Shape and Size</li> <li>Data Type</li> <li>Memory Layout</li> <li>Checking for NaN and Inf Values</li> </ul> </li> <li>Array Mathematics<ul> <li>Basic Operations</li> <li>Aggregate Functions</li> <li>Exponentials and Logarithms</li> <li>Trigonometric Functions</li> <li>Rounding and Precision Control</li> </ul> </li> <li>Array Manipulation<ul> <li>Reshaping</li> <li>Transposing</li> <li>Joining and Splitting Arrays</li> <li>Changing Dimensions</li> <li>Array Repetition</li> <li>Rotating and Flipping Arrays</li> </ul> </li> <li>Linear Algebra<ul> <li>Dot Product and Matrix Multiplication</li> <li>Solving Linear Equations</li> <li>Eigenvalues and Eigenvectors</li> <li>Inverse and Determinant</li> <li>Singular Value Decomposition (SVD)</li> <li>Norms and Condition Numbers</li> </ul> </li> <li>Statistics<ul> <li>Descriptive Statistics</li> <li>Percentiles</li> <li>Correlation and Covariance</li> <li>Histogram</li> <li>Binned Statistics</li> </ul> </li> <li>Broadcasting<ul> <li>Basic Broadcasting</li> <li>Advanced Broadcasting</li> </ul> </li> <li>Indexing and Slicing<ul> <li>Basic Indexing</li> <li>Slicing</li> <li>Fancy Indexing</li> </ul> </li> <li>Boolean Masking and Advanced Indexing<ul> <li>Boolean Masking</li> <li>Advanced Indexing with Conditions</li> <li>Setting Values</li> <li>Advanced Indexing with np.ix_</li> </ul> </li> <li>Random<ul> <li>Random Numbers</li> <li>Random Permutations</li> <li>Sampling and Distributions</li> <li>Setting Seed</li> </ul> </li> <li>I/O with NumPy<ul> <li>Reading and Writing Files</li> <li>Saving and Loading Multiple Arrays</li> <li>Reading and Writing CSV Files</li> <li>Reading and Writing with Pandas</li> </ul> </li> <li>Polynomials<ul> <li>Polynomial Operations</li> <li>Polynomial Fitting</li> <li>Polynomial Derivatives and Integrals</li> </ul> </li> <li>Advanced Array Operations<ul> <li>Vectorize Functions</li> <li>Meshgrid</li> <li>Broadcasting with Advanced Indexing</li> <li>Sorting Arrays</li> <li>Searching and Counting Elements</li> </ul> </li> <li>Memory Management<ul> <li>Memory Layout and Optimization</li> <li>Memory Mapping Files</li> <li>Copying and Views</li> </ul> </li> <li>Advanced Indexing<ul> <li>Using np.take and np.put</li> <li>Using np.choose</li> <li>Using np.lexsort</li> </ul> </li> <li>Matrix Operations<ul> <li>Determinant, Rank, and Trace</li> <li>Kronecker Product and Outer Product</li> <li>Solving Systems of Linear Equations</li> </ul> </li> <li>Data Types<ul> <li>Specifying Data Types</li> <li>Converting Data Types</li> <li>Complex Data Types</li> <li>Checking Data Types</li> </ul> </li> </ul> </li> </ul> <p>NumPy, which stands for Numerical Python, is a free, open-source Python library for working with arrays. It's one of the most popular packages for scientific computing in Python, and is used for data manipulation and analysis, including data cleaning, transformation, and aggregation.</p> <pre><code>import numpy as np\n</code></pre> <ul> <li>Official Website: https://numpy.org/</li> <li>Installation:  (https://numpy.org/install/)     <pre><code>pip install numpy\n</code></pre></li> <li>Documentation: https://numpy.org/doc</li> <li>GitHub: https://github.com/numpy/numpy</li> </ul>"},{"location":"Cheat-Sheets/NumPy_/#array-creation","title":"Array Creation","text":""},{"location":"Cheat-Sheets/NumPy_/#from-lists-tuples-and-buffers","title":"From Lists, Tuples, and Buffers","text":"<pre><code>np.array([1, 2, 3])\nnp.array((1, 2, 3))\nnp.frombuffer(b'Hello World', dtype='S1')\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#zeros-ones-and-empty-arrays","title":"Zeros, Ones, and Empty Arrays","text":"<pre><code>np.zeros((2, 3))  # 2x3 array of zeros\nnp.ones((2, 3))   # 2x3 array of ones\nnp.empty((2, 3))  # 2x3 empty array\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#ranges-and-random-numbers","title":"Ranges and Random Numbers","text":"<pre><code>np.arange(0, 10, 2)  # Array from 0 to 9 with step 2\nnp.linspace(0, 1, 5) # 5 equally spaced numbers from 0 to 1\nnp.random.rand(2, 3) # 2x3 array with random numbers between 0 and 1\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#identity-and-diagonal-matrices","title":"Identity and Diagonal Matrices","text":"<pre><code>np.eye(3)          # 3x3 identity matrix\nnp.diag([1, 2, 3]) # Diagonal matrix from a list\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#structured-arrays","title":"Structured Arrays","text":"<pre><code>dt = np.dtype([('age', np.int32), ('name', np.str_, 10)])\narr = np.array([(21, 'Alice'), (25, 'Bob')], dtype=dt)\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#using-npfull-and-nptile","title":"Using <code>np.full</code> and <code>np.tile</code>","text":"<pre><code>np.full((2, 3), 7)   # Create a 2x3 array filled with the value 7\nnp.tile([1, 2], (2, 3))  # Repeat [1, 2] in a 2x3 grid\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#array-inspection","title":"Array Inspection","text":""},{"location":"Cheat-Sheets/NumPy_/#shape-and-size","title":"Shape and Size","text":"<pre><code>arr.shape  # Dimensions of the array\narr.size   # Total number of elements\narr.ndim   # Number of dimensions\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#data-type","title":"Data Type","text":"<pre><code>arr.dtype  # Data type of elements\narr.astype(float)  # Convert to another type\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#memory-layout","title":"Memory Layout","text":"<pre><code>arr.itemsize  # Size of one element in bytes\narr.nbytes    # Total memory used by array\narr.flags     # Memory layout information\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#checking-for-nan-and-inf-values","title":"Checking for <code>NaN</code> and <code>Inf</code> Values","text":"<pre><code>np.isnan(arr)  # Check for NaN values\nnp.isinf(arr)  # Check for infinity values\nnp.isfinite(arr)  # Check for finite values\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#array-mathematics","title":"Array Mathematics","text":""},{"location":"Cheat-Sheets/NumPy_/#basic-operations","title":"Basic Operations","text":"<pre><code>arr + 1       # Add 1 to each element\narr * 2       # Multiply each element by 2\nnp.add(arr1, arr2)  # Add arrays element-wise\nnp.subtract(arr1, arr2)  # Subtract arrays element-wise\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#aggregate-functions","title":"Aggregate Functions","text":"<pre><code>np.sum(arr)       # Sum of all elements\nnp.mean(arr)      # Mean of elements\nnp.max(arr)       # Maximum value\nnp.min(arr)       # Minimum value\nnp.prod(arr)      # Product of elements\nnp.cumsum(arr)    # Cumulative sum of elements\nnp.cumprod(arr)   # Cumulative product of elements\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#exponentials-and-logarithms","title":"Exponentials and Logarithms","text":"<pre><code>np.exp(arr)       # Exponential of each element\nnp.log(arr)       # Natural logarithm\nnp.log10(arr)     # Base-10 logarithm\nnp.expm1(arr)     # Compute exp(x) - 1\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#trigonometric-functions","title":"Trigonometric Functions","text":"<pre><code>np.sin(arr)       # Sine of each element\nnp.cos(arr)       # Cosine of each element\nnp.tan(arr)       # Tangent of each element\nnp.arcsin(arr)    # Inverse sine\nnp.arccos(arr)    # Inverse cosine\nnp.arctan(arr)    # Inverse tangent\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#rounding-and-precision-control","title":"Rounding and Precision Control","text":"<pre><code>np.round(arr, decimals=2)  # Round to 2 decimal places\nnp.floor(arr)              # Floor operation\nnp.ceil(arr)               # Ceiling operation\nnp.trunc(arr)              # Truncate elements to integers\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#array-manipulation","title":"Array Manipulation","text":""},{"location":"Cheat-Sheets/NumPy_/#reshaping","title":"Reshaping","text":"<pre><code>arr.reshape((3, 2))  # Reshape to 3x2 array\narr.flatten()        # Flatten the array to 1D\nnp.ravel(arr)        # Return a flattened array\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#transposing","title":"Transposing","text":"<pre><code>arr.T            # Transpose of the array\nnp.transpose(arr, (1, 0, 2))  # Custom transpose\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#joining-and-splitting-arrays","title":"Joining and Splitting Arrays","text":"<pre><code>np.concatenate((arr1, arr2), axis=0)  # Join along axis 0\nnp.hstack((arr1, arr2))  # Horizontal stack\nnp.vstack((arr1, arr2))  # Vertical stack\nnp.split(arr, 3)         # Split into 3 equal parts\nnp.hsplit(arr, 2)        # Split horizontally\nnp.vsplit(arr, 2)        # Split vertically\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#changing-dimensions","title":"Changing Dimensions","text":"<pre><code>np.expand_dims(arr, axis=0)  # Expand dimensions\nnp.squeeze(arr)              # Remove single-dimensional entries\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#array-repetition","title":"Array Repetition","text":"<pre><code>np.tile(arr, (2, 3))  # Repeat array\nnp.repeat(arr, 3)     # Repeat elements of an array\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#rotating-and-flipping-arrays","title":"Rotating and Flipping Arrays","text":"<pre><code>np.rot90(arr)        # Rotate array by 90 degrees\nnp.fliplr(arr)       # Flip array left to right\nnp.flipud(arr)       # Flip array upside down\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#linear-algebra","title":"Linear Algebra","text":""},{"location":"Cheat-Sheets/NumPy_/#dot-product-and-matrix-multiplication","title":"Dot Product and Matrix Multiplication","text":"<pre><code>np.dot(arr1, arr2)       # Dot product\nnp.matmul(arr1, arr2)    # Matrix multiplication\narr1 @ arr2              # Matrix multiplication using @\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#solving-linear-equations","title":"Solving Linear Equations","text":"<pre><code>np.linalg.solve(A, b)    # Solve linear equations Ax = b\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#eigenvalues-and-eigenvectors","title":"Eigenvalues and Eigenvectors","text":"<pre><code>np.linalg.eig(arr)       # Eigenvalues and eigenvectors\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#inverse-and-determinant","title":"Inverse and Determinant","text":"<pre><code>np.linalg.inv(arr)       # Inverse of a matrix\nnp.linalg.det(arr)       # Determinant of a matrix\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#singular-value-decomposition-svd","title":"Singular Value Decomposition (SVD)","text":"<pre><code>U, S, V = np.linalg.svd(arr)  # Singular Value Decomposition\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#norms-and-condition-numbers","title":"Norms and Condition Numbers","text":"<pre><code>np.linalg.norm(arr)      # Compute matrix or vector norm\nnp.linalg.cond(arr)      # Compute the condition number of a matrix\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#statistics","title":"Statistics","text":""},{"location":"Cheat-Sheets/NumPy_/#descriptive-statistics","title":"Descriptive Statistics","text":"<pre><code>np.mean(arr)             # Mean\nnp.median(arr)           # Median\nnp.var(arr)              # Variance\nnp.std(arr)              # Standard deviation\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#percentiles","title":"Percentiles","text":"<pre><code>np.percentile(arr, 50)   # 50th percentile (median)\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#correlation-and-covariance","title":"Correlation and Covariance","text":"<pre><code>np.corrcoef(arr1, arr2)  # Correlation coefficient\nnp.cov(arr1, arr2)       # Covariance\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#histogram","title":"Histogram","text":"<pre><code>np.histogram(arr, bins=10)  # Histogram of an array\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#binned-statistics","title":"Binned Statistics","text":"<pre><code>from scipy import stats\nstats.binned_statistic(arr, values, statistic='mean', bins=10)  # Compute binned statistics\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#broadcasting","title":"Broadcasting","text":""},{"location":"Cheat-Sheets/NumPy_/#basic-broadcasting","title":"Basic Broadcasting","text":"<pre><code>arr + 5       # Add 5 to all elements\narr + [1, 2, 3]  # Add array [1, 2, 3] to each row\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#advanced-broadcasting","title":"Advanced Broadcasting","text":"<pre><code>arr * np.array([1, 2, 3])  # Element-wise multiplication with broadcasting\nnp.expand_dims(arr, axis=0) + arr  # Broadcasting with dimension expansion\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#indexing-and-slicing","title":"Indexing and Slicing","text":""},{"location":"Cheat-Sheets/NumPy_/#basic-indexing","title":"Basic Indexing","text":"<pre><code>arr[0]         # First element\narr\n\n[-1]        # Last element\narr[0, 2]      # First row, third column\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#slicing","title":"Slicing","text":"<pre><code>arr[1:3]       # Elements from index 1 to 2\narr[:, 1:3]    # All rows, columns 1 and 2\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#fancy-indexing","title":"Fancy Indexing","text":"<pre><code>arr[[0, 2], [1, 3]]  # Elements (0,1) and (2,3)\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#boolean-masking-and-advanced-indexing","title":"Boolean Masking and Advanced Indexing","text":""},{"location":"Cheat-Sheets/NumPy_/#boolean-masking","title":"Boolean Masking","text":"<pre><code>arr[arr &gt; 0]   # Elements greater than 0\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#advanced-indexing-with-conditions","title":"Advanced Indexing with Conditions","text":"<pre><code>np.where(arr &gt; 0, arr, -arr)  # Replace negative values with their absolute value\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#setting-values","title":"Setting Values","text":"<pre><code>arr[arr &gt; 0] = 0   # Set all positive elements to 0\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#advanced-indexing-with-npix_","title":"Advanced Indexing with np.ix_","text":"<pre><code>np.ix_([1, 3], [2, 4])  # Create a mesh grid from indexing arrays\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#random","title":"Random","text":""},{"location":"Cheat-Sheets/NumPy_/#random-numbers","title":"Random Numbers","text":"<pre><code>np.random.rand(2, 3)       # Uniform distribution (0, 1)\nnp.random.randn(2, 3)      # Standard normal distribution\nnp.random.randint(0, 10, size=(2, 3))  # Random integers between 0 and 9\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#random-permutations","title":"Random Permutations","text":"<pre><code>np.random.permutation(arr)  # Randomly permute an array\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#sampling-and-distributions","title":"Sampling and Distributions","text":"<pre><code>np.random.choice(arr, size=3, replace=False)  # Random sample without replacement\nnp.random.binomial(n=10, p=0.5, size=10)  # Binomial distribution\nnp.random.poisson(lam=3, size=10)         # Poisson distribution\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#setting-seed","title":"Setting Seed","text":"<pre><code>np.random.seed(42)  # Set random seed for reproducibility\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#io-with-numpy","title":"I/O with NumPy","text":""},{"location":"Cheat-Sheets/NumPy_/#reading-and-writing-files","title":"Reading and Writing Files","text":"<pre><code>np.save('array.npy', arr)    # Save array to binary file\nnp.load('array.npy')         # Load array from binary file\nnp.savetxt('array.txt', arr) # Save array to text file\nnp.loadtxt('array.txt')      # Load array from text file\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#saving-and-loading-multiple-arrays","title":"Saving and Loading Multiple Arrays","text":"<pre><code>np.savez('arrays.npz', arr1=arr1, arr2=arr2)  # Save multiple arrays to a compressed file\nnpzfile = np.load('arrays.npz')               # Load multiple arrays from a compressed file\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#reading-and-writing-csv-files","title":"Reading and Writing CSV Files","text":"<pre><code>np.genfromtxt('data.csv', delimiter=',')  # Load data from CSV file\nnp.savetxt('data.csv', arr, delimiter=',') # Save data to CSV file\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#reading-and-writing-with-pandas","title":"Reading and Writing with Pandas","text":"<pre><code>import pandas as pd\ndf = pd.read_csv('data.csv')  # Load data into a Pandas DataFrame\ndf.to_csv('output.csv')       # Save DataFrame to a CSV file\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#polynomials","title":"Polynomials","text":""},{"location":"Cheat-Sheets/NumPy_/#polynomial-operations","title":"Polynomial Operations","text":"<pre><code>p = np.poly1d([1, 2, 3])  # Define a polynomial p(x) = 1x^2 + 2x + 3\np(2)                      # Evaluate polynomial at x = 2\np.roots                   # Find roots of the polynomial\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#polynomial-fitting","title":"Polynomial Fitting","text":"<pre><code>np.polyfit(x, y, deg=2)  # Fit a polynomial of degree 2 to data points (x, y)\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#polynomial-derivatives-and-integrals","title":"Polynomial Derivatives and Integrals","text":"<pre><code>p.deriv()  # Derivative of the polynomial\np.integ()  # Integral of the polynomial\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#advanced-array-operations","title":"Advanced Array Operations","text":""},{"location":"Cheat-Sheets/NumPy_/#vectorize-functions","title":"Vectorize Functions","text":"<pre><code>vectorized_func = np.vectorize(some_function)  # Apply a function element-wise to an array\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#meshgrid","title":"Meshgrid","text":"<pre><code>X, Y = np.meshgrid(x, y)  # Create a coordinate grid from 1D arrays x and y\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#broadcasting-with-advanced-indexing","title":"Broadcasting with Advanced Indexing","text":"<pre><code>np.add.at(arr, idx, 1)  # Increment elements at indices `idx` by 1\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#sorting-arrays","title":"Sorting Arrays","text":"<pre><code>np.sort(arr)            # Sort array\nnp.argsort(arr)         # Indices of the sorted array\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#searching-and-counting-elements","title":"Searching and Counting Elements","text":"<pre><code>np.where(arr &gt; 0)       # Indices where the condition is met\nnp.count_nonzero(arr)   # Count non-zero elements\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#memory-management","title":"Memory Management","text":""},{"location":"Cheat-Sheets/NumPy_/#memory-layout-and-optimization","title":"Memory Layout and Optimization","text":"<pre><code>arr.flags           # Check memory layout (C_CONTIGUOUS, F_CONTIGUOUS)\nnp.ascontiguousarray(arr)  # Convert to C-contiguous array\nnp.asfortranarray(arr)     # Convert to Fortran-contiguous array\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#memory-mapping-files","title":"Memory Mapping Files","text":"<pre><code>np.memmap('data.dat', dtype='float32', mode='w+', shape=(1000, 1000))  # Memory-mapped file\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#copying-and-views","title":"Copying and Views","text":"<pre><code>arr_copy = arr.copy()  # Create a deep copy of the array\narr_view = arr.view()  # Create a view of the array (shallow copy)\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#advanced-indexing","title":"Advanced Indexing","text":""},{"location":"Cheat-Sheets/NumPy_/#using-nptake-and-npput","title":"Using <code>np.take</code> and <code>np.put</code>","text":"<pre><code>np.take(arr, [0, 2])   # Take elements at indices 0 and 2\nnp.put(arr, [0, 2], [-1, -2])  # Set elements at indices 0 and 2\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#using-npchoose","title":"Using <code>np.choose</code>","text":"<pre><code>np.choose([0, 1], [arr1, arr2])  # Construct an array from elements chosen from `arr1` and `arr2`\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#using-nplexsort","title":"Using <code>np.lexsort</code>","text":"<pre><code>np.lexsort((arr2, arr1))  # Sort by `arr1`, then by `arr2`\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#matrix-operations","title":"Matrix Operations","text":""},{"location":"Cheat-Sheets/NumPy_/#determinant-rank-and-trace","title":"Determinant, Rank, and Trace","text":"<pre><code>np.linalg.det(arr)   # Determinant of a matrix\nnp.linalg.matrix_rank(arr)  # Rank of a matrix\nnp.trace(arr)  # Sum of diagonal elements (trace)\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#kronecker-product-and-outer-product","title":"Kronecker Product and Outer Product","text":"<pre><code>np.kron(arr1, arr2)  # Kronecker product of two arrays\nnp.outer(arr1, arr2) # Outer product of two arrays\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#solving-systems-of-linear-equations","title":"Solving Systems of Linear Equations","text":"<pre><code>np.linalg.solve(A, b)   # Solve Ax = b for x\nnp.linalg.lstsq(A, b)   # Solve Ax = b using least squares\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#data-types","title":"Data Types","text":""},{"location":"Cheat-Sheets/NumPy_/#specifying-data-types","title":"Specifying Data Types","text":"<pre><code>arr = np.array([1, 2, 3], dtype=np.float32)  # Specify data type\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#converting-data-types","title":"Converting Data Types","text":"<pre><code>arr.astype(np.int32)  # Convert array to specified data type\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#complex-data-types","title":"Complex Data Types","text":"<pre><code>arr = np.array([1+2j, 3+4j], dtype=np.complex64)  # Complex data type\n</code></pre>"},{"location":"Cheat-Sheets/NumPy_/#checking-data-types","title":"Checking Data Types","text":"<pre><code>arr.dtype    # Check data type\nnp.issubdtype(arr.dtype, np.number)  # Check if the data type is a subtype of `np.number`\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/","title":"Home","text":""},{"location":"Deploying-ML-models/deploying-ml-models/#introduction","title":"Introduction","text":"<p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#contribute-to-the-platform","title":"Contribute to the platform","text":"<p>Contribution in any form will be deeply appreciated. \ud83d\ude4f</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#add-questions","title":"Add questions","text":"<p>\u2753 Add your questions here. Please ensure to provide a detailed description to allow your fellow contributors to understand your questions and answer them to your satisfaction.</p> <p></p> <p>\ud83e\udd1d Please note that as of now, you cannot directly add a question via a pull request. This will help us to maintain the quality of the content for you.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#add-answerstopics","title":"Add answers/topics","text":"<p>\ud83d\udcdd These are the answers/topics that need your help at the moment</p> <ul> <li> Add documentation for the project</li> <li> Online Material for Learning</li> <li> Suggested Learning Paths</li> <li> Cheat Sheets<ul> <li> Django</li> <li> Flask</li> <li> Numpy</li> <li> Pandas</li> <li> PySpark</li> <li> Python</li> <li> RegEx</li> <li> SQL</li> </ul> </li> <li> NLP Interview Questions</li> <li> Add python common DSA interview questions</li> <li> Add Major ML topics<ul> <li> Linear Regression </li> <li> Logistic Regression </li> <li> SVM </li> <li> Random Forest </li> <li> Gradient boosting </li> <li> PCA </li> <li> Collaborative Filtering </li> <li> K-means clustering </li> <li> kNN </li> <li> ARIMA </li> <li> Neural Networks </li> <li> Decision Trees </li> <li> Overfitting, Underfitting</li> <li> Unbalanced, Skewed data</li> <li> Activation functions relu/ leaky relu</li> <li> Normalization</li> <li> DBSCAN </li> <li> Normal Distribution </li> <li> Precision, Recall </li> <li> Loss Function MAE, RMSE </li> </ul> </li> <li> Add Pandas questions</li> <li> Add NumPy questions</li> <li> Add TensorFlow questions</li> <li> Add PyTorch questions</li> <li> Add list of learning resources</li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#reportsolve-issues","title":"Report/Solve Issues","text":"<p>\ud83d\udd27 To report any issues find me on LinkedIn or raise an issue on GitHub.</p> <p>\ud83d\udee0 You can also solve existing issues on GitHub and create a pull request.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#say-thanks","title":"Say Thanks","text":"<p>\ud83d\ude0a If this platform helped you in any way, it would be great if you could share it with others.</p> <p> </p> <pre><code>Check out this \ud83d\udc47 platform \ud83d\udc47 for data science content:\n\ud83d\udc49 https://singhsidhukuldeep.github.io/data-science-interview-prep/ \ud83d\udc48\n\n#data-science #machine-learning #interview-preparation \n</code></pre> <p>You can also star the repository on GitHub    and watch-out for any updates </p>"},{"location":"Deploying-ML-models/deploying-ml-models/#features","title":"Features","text":"<ul> <li> <p>\ud83c\udfa8 Beautiful: The design is built on top of most popular libraries like MkDocs and material which allows the platform to be responsive and to work on all sorts of devices \u2013 from mobile phones to wide-screens. The underlying fluid layout will always adapt perfectly to the available screen space.</p> </li> <li> <p>\ud83e\uddd0 Searchable: almost magically, all the content on the website is searchable without any further ado. The built-in search \u2013 server-less \u2013 is fast and accurate in responses to any of the queries.</p> </li> <li> <p>\ud83d\ude4c Accessible:</p> <ul> <li>Easy to use: \ud83d\udc4c The website is hosted on github-pages and is free and open to use to over 40 million users of GitHub in 100+ countries.</li> <li>Easy to contribute: \ud83e\udd1d The website embodies the concept of collaboration to the latter. Allowing anyone to add/improve the content. To make contributing easy, everything is written in MarkDown and then compiled to beautiful html.</li> </ul> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#setup","title":"Setup","text":"<p>No setup is required for usage of the platform</p> <p>Important: It is strongly advised to use virtual environment and not change anything in <code>gh-pages</code></p>"},{"location":"Deploying-ML-models/deploying-ml-models/#linux-systems","title":"<code>Linux</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nsource venv/bin/activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>deactivate\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#windows-systems","title":"<code>Windows</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nvenv\\Scripts\\activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>venv\\Scripts\\deactivate\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#to-install-the-latest","title":"To install the latest","text":"<pre><code>pip3 install mkdocs\npip3 install mkdocs-material\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#useful-commands","title":"Useful Commands","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Use\u00a0<code>mkdocs gh-deploy --help</code>\u00a0to get a full list of options available for the\u00a0<code>gh-deploy</code>\u00a0command.     Be aware that you will not be able to review the built site before it is pushed to GitHub. Therefore, you may want to verify any changes you make to the docs beforehand by using the\u00a0<code>build</code>\u00a0or\u00a0<code>serve</code>\u00a0commands and reviewing the built files locally.</li> <li><code>mkdocs new [dir-name]</code> - Create a new project. No need to create a new project</li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#useful-documents","title":"Useful Documents","text":"<ul> <li> <p>\ud83d\udcd1 MkDocs: https://github.com/mkdocs/mkdocs</p> </li> <li> <p>\ud83c\udfa8 Theme: https://github.com/squidfunk/mkdocs-material</p> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#faq","title":"FAQ","text":"<ul> <li> <p>Can I filter questions based on companies? \ud83e\udd2a</p> <p>As much as this platform aims to help you with your interview preparation, it is not a short-cut to crack one. Think of this platform as a practicing field to help you sharpen your skills for your interview processes. However, for your convenience we have sorted all the questions by topics for you. \ud83e\udd13</p> <p>This doesn't mean that such feature won't be added in the future.  \"Never say Never\"</p> <p>But as of now there is neither plan nor data to do so. \ud83d\ude22</p> </li> <li> <p>Why is this platform free? \ud83e\udd17</p> <p>Currently there is no major cost involved in maintaining this platform other than time and effort that is put in by every contributor.  If you want to help you can contribute here. </p> <p>If you still want to pay for something that is free, we would request you to donate it to a charity of your choice instead. \ud83d\ude07</p> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#credits","title":"Credits","text":""},{"location":"Deploying-ML-models/deploying-ml-models/#maintained-by","title":"Maintained by","text":"<p>\ud83d\udc68\u200d\ud83c\udf93 Kuldeep Singh Sidhu </p> <p>Github: github/singhsidhukuldeep <code>https://github.com/singhsidhukuldeep</code></p> <p>Website: Kuldeep Singh Sidhu (Website) <code>http://kuldeepsinghsidhu.com</code></p> <p>LinkedIn: Kuldeep Singh Sidhu (LinkedIn) <code>https://www.linkedin.com/in/singhsidhukuldeep/</code></p>"},{"location":"Deploying-ML-models/deploying-ml-models/#contributors","title":"Contributors","text":"<p>\ud83d\ude0e The full list of all the contributors is available here</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#current-status","title":"Current Status","text":""},{"location":"Interview-Questions/Interview-Questions/","title":"Interview Questions (Intro)","text":"<p>These are currently most commonly asked questions. Questions can be removed if they are no longer popular in interview circles and added as new question banks are released.</p>"},{"location":"Interview-Questions/Natural-Language-Processing/","title":"NLP Interview Questions","text":""},{"location":"Interview-Questions/Probability/","title":"Probability Interview Questions","text":"<ul> <li>Probability Interview Questions<ul> <li>Average score on a dice role of at most 3 times</li> </ul> </li> </ul>"},{"location":"Interview-Questions/Probability/#average-score-on-a-dice-role-of-at-most-3-times","title":"Average score on a dice role of at most 3 times","text":"<p>Question</p> <p>Consider a fair 6-sided dice.  Your aim is to get the highest score you can, in at-most 3 roles.</p> <p>A score is defined as the number that appears on the face of the dice facing up after the role.  You can role at most 3 times but every time you role it is up to you to decide whether you want to role again.</p> <p>The last score will be counted as your final score.</p> <ul> <li>Find the average score if you rolled the dice only once?</li> <li>Find the average score that you can get with at most 3 roles?</li> <li>If the dice is fair, why is the average score for at most 3 roles and 1 role not the same?</li> </ul> Hint 1 <p>Find what is the expected score on single role</p> <p>And for cases when scores of single role &lt; <code>expected score on single role</code>  is when you will go for next role</p> <p>Eg: if expected score of single role comes out to be 4.5,  you will only role next turn for 1,2,3,4 and not for 5,6</p> Answer <p>If you role a fair dice once you can get:</p> Score Probability 1 \u2159 2 \u2159 3 \u2159 4 \u2159 5 \u2159 6 \u2159 <p>So your average score with one role is: </p> <p><code>sum of(score * scores's probability)</code> = (1+2+3+4+5+6)*(\u2159) = (21/6) = 3.5</p> <p>The average score if you rolled the dice only once is 3.5</p> <p>For at most 3 roles, let's try back-tracking. Let's say just did your second role and you have to decide whether to do your 3<sup>rd</sup> role!</p> <p>We just found out if we role dice once on average we can expect score of 3.5. So we will only role the 3<sup>rd</sup> time if score on 2<sup>nd</sup> role is less than 3.5 i.e (1,2 or 3)</p> <p>Possibilities</p> 2<sup>nd</sup> role score Probability 3<sup>rd</sup> role score Probability 1 \u2159 3.5 \u2159 2 \u2159 3.5 \u2159 3 \u2159 3.5 \u2159 4 \u2159 NA We won't role 5 \u2159 NA 3<sup>rd</sup> time if we 6 \u2159 NA get score &gt;3 on 2<sup>nd</sup> <p>So if we had 2 roles, average score would be:</p> <pre><code>[We role again if current score is less than 3.4]\n(3.5)*(1/6) + (3.5)*(1/6) + (3.5)*(1/6) \n+\n(4)*(1/6) + (5)*(1/6) + (6)*(1/6) [Decide not to role again]\n=\n1.75 + 2.5 = 4.25\n</code></pre> <p>The average score if you rolled the dice twice is 4.25</p> <p>So now if we look from the perspective of first role. We will only role again if our score is less than 4.25 i.e 1,2,3 or 4</p> <p>Possibilities</p> 1<sup>st</sup> role score Probability 2<sup>nd</sup> and 3<sup>rd</sup> role score Probability 1 \u2159 4.25 \u2159 2 \u2159 4.25 \u2159 3 \u2159 4.25 \u2159 4 \u2159 4.25 \u2159 5 \u2159 NA We won't role again if we 6 \u2159 NA get score &gt;4.25 on 1<sup>st</sup> <p>So if we had 3 roles, average score would be:</p> <p><pre><code>[We role again if current score is less than 4.25]\n(4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) \n+\n(5)*(1/6) + (6)*(1/6) [[Decide not to role again]\n=\n17/6 + 11/6 = 4.66\n</code></pre> The average score if you rolled the dice only once is 4.66</p> <p>The average score for at most 3 roles and 1 role is not the same because although the dice is fair the event of rolling the dice is no longer independent. The scores would have been the same if we rolled the dice 2<sup>nd</sup> and 3<sup>rd</sup> time without considering what we got in the last roll i.e. if the event of rolling the dice was independent.</p>"},{"location":"Interview-Questions/System-design/","title":"System Design","text":""},{"location":"Interview-Questions/data-structures-algorithms/","title":"Data Structure and Algorithms (DSA)","text":"<ul> <li>Data Structure and Algorithms (DSA)<ul> <li>To-do</li> <li>\ud83d\ude01 Easy<ul> <li>Two Number Sum</li> <li>Validate Subsequence</li> <li>Nth Fibonacci</li> <li>Product Sum</li> </ul> </li> <li>\ud83d\ude42 Medium<ul> <li>Top K Frequent Words</li> </ul> </li> <li>\ud83e\udd28 Hard</li> <li>\ud83d\ude32 Very Hard</li> </ul> </li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#to-do","title":"To-do","text":"<ul> <li> Add https://leetcode.com/discuss/interview-question/344650/Amazon-Online-Assessment-Questions</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#easy","title":"\ud83d\ude01 Easy","text":""},{"location":"Interview-Questions/data-structures-algorithms/#two-number-sum","title":"Two Number Sum","text":"<p>Question</p> <p>Write a function that takes in a non-empty array of distinct integers and an integer representing a target sum. </p> <p>If any two numbers in the input array sum up to the target sum, the function should return them in an array, in any order. </p> <p>If no two numbers sum up to the target sum, the function should return an empty array.</p> Try it! <ul> <li>LeetCode: https://leetcode.com/problems/two-sum/</li> </ul> Hint 1 <p>No Hint</p> Answer <p><pre><code># O(n) time | O(n) space\ndef twoNumberSum(array, targetSum):\n    avail = set()\n    for i,v in enumerate(array):\n        if targetSum-v in avail:\n            return [targetSum-v,v]\n        else:\n            avail.add(v)\n    return []\n    pass\n</code></pre> <pre><code># O(nlog(n)) time | O(1) space\ndef twoNumberSum(array, targetSum):\n    array.sort()\n    n = len(array)\n    left = 0\n    right = n-1\n    while left&lt;right:\n        currSum = array[left]+array[right]\n        if currSum==targetSum: return [array[left], array[right]]\n        elif currSum&lt;targetSum: left+=1\n        elif currSum&gt;targetSum: right-=1\n    return []\n    pass\n</code></pre> <pre><code># O(n^2) time | O(1) space\ndef twoNumberSum(array, targetSum):\n    n = len(array)\n    for i in range(n-1):\n        for j in range(i+1,n):\n            if array[i]+array[j] == targetSum:\n                return [array[i],array[j]]\n    return []\n    pass\n</code></pre></p>"},{"location":"Interview-Questions/data-structures-algorithms/#validate-subsequence","title":"Validate Subsequence","text":"<p>Question</p> <p>Given two non-empty arrays of integers, write a function that determines whether the second array is a subsequence of the first one.</p> <p>A subsequence of an array is a set of numbers that aren't necessarily adjacent in the array but that are in the same order as they appear in the array. For instance, the numbers [1, 3, 4]  form a subsequence of the array [1, 2, 3, 4] , and so do the numbers [2, 4].</p> <p>Note that a single number in an array and the array itself are both valid subsequences of the array.</p> Try it! <ul> <li>GeeksforGeeks: https://www.geeksforgeeks.org/problems/array-subset-of-another-array2317/1</li> </ul> Hint 1 <p>No Hint</p> Answer <pre><code># O(n) time | O(1) space - where n is the length of the array\ndef isValidSubsequence(array, sequence):\n    pArray = pSequence = 0\n    while pArray &lt; len(array) and pSequence &lt; len(sequence):\n        if array[pArray] == sequence[pSequence]:\n            pArray+=1\n            pSequence+=1\n        else: pArray+=1\n    return pSequence == len(sequence)\n    pass\n</code></pre>"},{"location":"Interview-Questions/data-structures-algorithms/#nth-fibonacci","title":"Nth Fibonacci","text":"<p>Question</p> <p>The Fibonacci sequence is defined as follows: Any number in the sequence is the sum of the previous 2.</p> <p>for <code>fib[n] = fib[n-1] + fib[n-2]</code></p> <p>The 1<sup>st</sup> and 2<sup>nd</sup> are fixed at 0,1</p> <p>Find the nth Nth Fibonacci sequence</p> Try it! <ul> <li>LeetCode: https://leetcode.com/problems/fibonacci-number/</li> <li>GeeksforGeeks: https://www.geeksforgeeks.org/problems/nth-fibonacci-number1335/1</li> </ul> Hint 1 <p>No Hint</p> Answer <pre><code># O(n) time | O(n) space\ndef getNthFib(n):\n    dp = [0,1]\n    while len(dp)&lt;n:\n        dp.append(dp[-1]+dp[-2])\n    return dp[n-1]\n    pass\n</code></pre> <pre><code># O(n) time | O(1) space\ndef getNthFib(n):\n    last_two = [0,1]\n    count = 2\n    while count &lt; n:\n        currFib = last_two[0] + last_two[1]\n        last_two[0] = last_two[1]\n        last_two[1] = currFib\n        count += 1\n    return last_two[1] if n&gt;1 else last_two[0]\n    pass\n</code></pre>"},{"location":"Interview-Questions/data-structures-algorithms/#product-sum","title":"Product Sum","text":"<p>Question</p> <p>Write a function that takes in a \"special\" array and returns its product sum. A \"special\" array is a non-empty array that contains either integers or other \"special\" arrays. The product sum of a \"special\" array is the sum of its elements, where \"special\" arrays inside it are summed themselves and then multiplied by their level of depth.</p> <p>For example, the product sum of <code>[x, y]</code> is <code>x + y</code> ; the product sum of <code>[x, [y, z]]</code> is <code>x + 2y + 2z</code></p> <p>Eg: Input: <code>[5, 2, [7, -1], 3, [6, [-13, 8], 4]]</code> Output: <code>12 # calculated as: 5 + 2 + 2 * (7 - 1) + 3 + 2 * (6 + 3 * (-13 + 8) + 4)</code></p> Try it! <ul> <li>LeetCode: https://leetcode.com/problems/fibonacci-number/</li> <li>GeeksforGeeks: https://www.geeksforgeeks.org/problems/nth-fibonacci-number1335/1</li> </ul> Hint 1 <p>No Hint</p> Answer <pre><code># O(n) time | O(d) space - where n is the total number of elements in the array,\n# including sub-elements, and d is the greatest depth of \"special\" arrays in the array\ndef productSum(array, depth = 1):\n    sum = 0\n    for i,v in enumerate(array):\n        if type(v) is list:\n            sum += productSum(v, depth + 1)\n        else:\n            sum += v\n    return sum*depth\n    pass\n</code></pre>"},{"location":"Interview-Questions/data-structures-algorithms/#medium","title":"\ud83d\ude42 Medium","text":""},{"location":"Interview-Questions/data-structures-algorithms/#top-k-frequent-words","title":"Top K Frequent Words","text":"<p>Question</p> <p>Given a non-empty list of words, return the\u00a0k\u00a0most frequent elements.</p> <p>Your answer should be sorted by frequency from highest to lowest. If two words have the same frequency, then the word with the lower alphabetical order comes first.</p> <p>Example 1:</p> <pre><code>Input: [\"i\", \"love\", \"leetcode\", \"i\", \"love\", \"coding\"], k = 2\nOutput: [\"i\", \"love\"]\nExplanation: \"i\" and \"love\" are the two most frequent words.\n    Note that \"i\" comes before \"love\" due to a lower alphabetical order.\n</code></pre> <p>Example 2:</p> <p><pre><code>Input: [\"the\", \"day\", \"is\", \"sunny\", \"the\", \"the\", \"the\", \"sunny\", \"is\", \"is\"], k = 4\nOutput: [\"the\", \"is\", \"sunny\", \"day\"]\nExplanation: \"the\", \"is\", \"sunny\" and \"day\" are the four most frequent words,\n    with the number of occurrence being 4, 3, 2 and 1 respectively.\n</code></pre> Note:</p> <ol> <li>You may assume\u00a0k\u00a0is always valid, 1 \u2264\u00a0k\u00a0\u2264 number of unique elements.</li> <li>Input words contain only lowercase letters.</li> </ol> <p>Follow up:</p> <ol> <li>Try to solve it in\u00a0O(n\u00a0log\u00a0k) time and\u00a0O(n) extra space.</li> </ol> Try it! <ul> <li>LeetCode: https://leetcode.com/problems/top-k-frequent-words/</li> </ul> Hint 1 <p>No Hint</p> Answer <pre><code># Count the frequency of each word, and \n# sort the words with a custom ordering relation \n# that uses these frequencies. Then take the best k of them.\n\n# Time Complexity: O(N \\log{N})O(NlogN), where NN is the length of words. \n# We count the frequency of each word in O(N)O(N) time, \n# then we sort the given words in O(N \\log{N})O(NlogN) time.\n# Space Complexity: O(N)O(N), the space used to store our uniqueWords.\ndef topKFrequentWords(words, k)-&gt; List[str]:\n    from collections import Counter\n    wordsFreq = Counter(words)\n    uniqueWords = list(wordsFreq.keys())\n    uniqueWords.sort(key = lambda x: (-wordsFreq[x], x))\n    return uniqueWords[:k]\n</code></pre> <pre><code># Time Complexity: O(N \\log{k})O(Nlogk), where NN is the length of words. \n# We count the frequency of each word in O(N)O(N) time, then we add NN words to the heap, \n# each in O(\\log {k})O(logk) time. Finally, we pop from the heap up to kk times. \n# As k \\leq Nk\u2264N, this is O(N \\log{k})O(Nlogk) in total.\n\n# In Python, we improve this to O(N + k \\log {N})O(N+klogN): our heapq.heapify operation and \n# counting operations are O(N)O(N), and \n# each of kk heapq.heappop operations are O(\\log {N})O(logN).\n\n# Space Complexity: O(N)O(N), the space used to store our wordsFreq.\n\n# Count the frequency of each word, then add it to heap that stores the best k candidates. \n# Here, \"best\" is defined with our custom ordering relation, \n# which puts the worst candidates at the top of the heap. \n# At the end, we pop off the heap up to k times and reverse the result \n# so that the best candidates are first.\n\n# In Python, we instead use heapq.heapify, which can turn a list into a heap in linear time, \n# simplifying our work.\n\ndef topKFrequentWords(words, k)-&gt; List[str]:\n    from heapq import heapify, heappop#, heappush\n    from collections import Counter\n    wordsFreq = Counter(words)\n    heap = [(-freq, word) for word, freq in wordsFreq.items()]\n    heapq.heapify(heap)\n    return [heapq.heappop(heap)[1] for _ in range(k)]\n</code></pre>"},{"location":"Interview-Questions/data-structures-algorithms/#hard","title":"\ud83e\udd28 Hard","text":""},{"location":"Interview-Questions/data-structures-algorithms/#very-hard","title":"\ud83d\ude32 Very Hard","text":""}]}