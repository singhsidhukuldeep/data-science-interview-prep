{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews.</p> <ul> <li>  Interview Questions <p>These are currently most commonly asked interview questions. </p> <p>Questions can be removed if they are no longer popular in interview circles and added as new question banks are released.</p> <ul> <li>DSA (Data Structures &amp; Algorithms)</li> <li>System Design</li> <li>Natural Language Processing (NLP)</li> <li>Probability</li> </ul> </li> <li> Cheat Sheets <p>Distilled down important concepts for your quick reference</p> </li> <li> ML Algorithms <p>From scratch implementation and documentation of all ML algorithms</p> </li> <li> Online Resources <p>Most popular and commonly reffered online resources</p> </li> </ul> Current Platform Status  Done Under Development To Do <ul> <li>Cheat-Sheets/Hypothesis-Tests/</li> </ul> <ol> <li>I</li> <li>Will</li> <li>Update</li> <li>Soon</li> </ol> <ol> <li>I</li> <li>Will</li> <li>Update</li> <li>Soon</li> </ol> <ul> <li>:: Project Maintainer</li> <li> All Contributors list</li> <li> AGPL-3.0 license</li> <li> Reach Out</li> </ul>"},{"location":"Introduction/","title":"Home","text":""},{"location":"Introduction/#introduction","title":"Introduction","text":"<p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews.</p>"},{"location":"Introduction/#contribute-to-the-platform","title":"Contribute to the platform","text":"<p>Contribution in any form will be deeply appreciated. \ud83d\ude4f</p>"},{"location":"Introduction/#add-questions","title":"Add questions","text":"<p>\u2753 Add your questions here. Please ensure to provide a detailed description to allow your fellow contributors to understand your questions and answer them to your satisfaction.</p> <p></p> <p>\ud83e\udd1d Please note that as of now, you cannot directly add a question via a pull request. This will help us to maintain the quality of the content for you.</p>"},{"location":"Introduction/#add-answerstopics","title":"Add answers/topics","text":"<p>\ud83d\udcdd These are the answers/topics that need your help at the moment</p> <ul> <li> Add documentation for the project</li> <li> Online Material for Learning</li> <li> Suggested Learning Paths</li> <li> Cheat Sheets<ul> <li> Django</li> <li> Flask</li> <li> Numpy</li> <li> Pandas</li> <li> PySpark</li> <li> Python</li> <li> RegEx</li> <li> SQL</li> </ul> </li> <li> NLP Interview Questions</li> <li> Add python common DSA interview questions</li> <li> Add Major ML topics<ul> <li> Linear Regression </li> <li> Logistic Regression </li> <li> SVM </li> <li> Random Forest </li> <li> Gradient boosting </li> <li> PCA </li> <li> Collaborative Filtering </li> <li> K-means clustering </li> <li> kNN </li> <li> ARIMA </li> <li> Neural Networks </li> <li> Decision Trees </li> <li> Overfitting, Underfitting</li> <li> Unbalanced, Skewed data</li> <li> Activation functions relu/ leaky relu</li> <li> Normalization</li> <li> DBSCAN </li> <li> Normal Distribution </li> <li> Precision, Recall </li> <li> Loss Function MAE, RMSE </li> </ul> </li> <li> Add Pandas questions</li> <li> Add NumPy questions</li> <li> Add TensorFlow questions</li> <li> Add PyTorch questions</li> <li> Add list of learning resources</li> </ul>"},{"location":"Introduction/#reportsolve-issues","title":"Report/Solve Issues","text":"<p>\ud83d\udd27 To report any issues find me on LinkedIn or raise an issue on GitHub.</p> <p>\ud83d\udee0 You can also solve existing issues on GitHub and create a pull request.</p>"},{"location":"Introduction/#say-thanks","title":"Say Thanks","text":"<p>\ud83d\ude0a If this platform helped you in any way, it would be great if you could share it with others.</p> <p> </p> <pre><code>Check out this \ud83d\udc47 platform \ud83d\udc47 for data science content:\n\ud83d\udc49 https://singhsidhukuldeep.github.io/data-science-interview-prep/ \ud83d\udc48\n</code></pre> <p>You can also star the repository on GitHub    and watch-out for any updates </p>"},{"location":"Introduction/#features","title":"Features","text":"<ul> <li> <p>\ud83c\udfa8 Beautiful: The design is built on top of most popular libraries like MkDocs and material which allows the platform to be responsive and to work on all sorts of devices \u2013 from mobile phones to wide-screens. The underlying fluid layout will always adapt perfectly to the available screen space.</p> </li> <li> <p>\ud83e\uddd0 Searchable: almost magically, all the content on the website is searchable without any further ado. The built-in search \u2013 server-less \u2013 is fast and accurate in responses to any of the queries.</p> </li> <li> <p>\ud83d\ude4c Accessible:</p> <ul> <li>Easy to use: \ud83d\udc4c The website is hosted on github-pages and is free and open to use to over 40 million users of GitHub in 100+ countries.</li> <li>Easy to contribute: \ud83e\udd1d The website embodies the concept of collaboration to the latter. Allowing anyone to add/improve the content. To make contributing easy, everything is written in MarkDown and then compiled to beautiful html.</li> </ul> </li> </ul>"},{"location":"Introduction/#setup","title":"Setup","text":"<p>No setup is required for usage of the platform</p> <p>Important: It is strongly advised to use virtual environment and not change anything in <code>gh-pages</code></p>"},{"location":"Introduction/#linux-systems","title":"<code>Linux</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nsource venv/bin/activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>deactivate\n</code></pre>"},{"location":"Introduction/#windows-systems","title":"<code>Windows</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nvenv\\Scripts\\activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>venv\\Scripts\\deactivate\n</code></pre>"},{"location":"Introduction/#to-install-the-latest","title":"To install the latest","text":"<pre><code>pip3 install mkdocs\npip3 install mkdocs-material\npip3 install mkdocs-minify-plugin\npip3 install mkdocs-git-revision-date-localized-plugin\n</code></pre>"},{"location":"Introduction/#useful-commands","title":"Useful Commands","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Use\u00a0<code>mkdocs gh-deploy --help</code>\u00a0to get a full list of options available for the\u00a0<code>gh-deploy</code>\u00a0command.     Be aware that you will not be able to review the built site before it is pushed to GitHub. Therefore, you may want to verify any changes you make to the docs beforehand by using the\u00a0<code>build</code>\u00a0or\u00a0<code>serve</code>\u00a0commands and reviewing the built files locally.</li> <li><code>mkdocs new [dir-name]</code> - Create a new project. No need to create a new project</li> </ul>"},{"location":"Introduction/#useful-documents","title":"Useful Documents","text":"<ul> <li> <p>\ud83d\udcd1 MkDocs: </p> <ul> <li>GitHub: https://github.com/mkdocs/mkdocs</li> <li>Documentation: https://www.mkdocs.org/</li> </ul> </li> <li> <p>\ud83c\udfa8 Theme: </p> <ul> <li>GitHub: https://github.com/squidfunk/mkdocs-material</li> <li>Documentation: https://squidfunk.github.io/mkdocs-material/getting-started/</li> </ul> </li> </ul>"},{"location":"Introduction/#faq","title":"FAQ","text":"<ul> <li> <p>Can I filter questions based on companies? \ud83e\udd2a</p> <p>As much as this platform aims to help you with your interview preparation, it is not a short-cut to crack one. Think of this platform as a practicing field to help you sharpen your skills for your interview processes. However, for your convenience we have sorted all the questions by topics for you. \ud83e\udd13</p> <p>This doesn't mean that such feature won't be added in the future.  \"Never say Never\"</p> <p>But as of now there is neither plan nor data to do so. \ud83d\ude22</p> </li> <li> <p>Why is this platform free? \ud83e\udd17</p> <p>Currently there is no major cost involved in maintaining this platform other than time and effort that is put in by every contributor.  If you want to help you can contribute here. </p> <p>If you still want to pay for something that is free, we would request you to donate it to a charity of your choice instead. \ud83d\ude07</p> </li> </ul>"},{"location":"Introduction/#credits","title":"Credits","text":""},{"location":"Introduction/#maintained-by","title":"Maintained by","text":"<p>\ud83d\udc68\u200d\ud83c\udf93 Kuldeep Singh Sidhu </p> <p>Github: github/singhsidhukuldeep <code>https://github.com/singhsidhukuldeep</code></p> <p>Website: Kuldeep Singh Sidhu (Website) <code>http://kuldeepsinghsidhu.com</code></p> <p>LinkedIn: Kuldeep Singh Sidhu (LinkedIn) <code>https://www.linkedin.com/in/singhsidhukuldeep/</code></p>"},{"location":"Introduction/#contributors","title":"Contributors","text":"<p>\ud83d\ude0e The full list of all the contributors is available here</p>"},{"location":"Introduction/#current-status","title":"Current Status","text":""},{"location":"contact/","title":"Contact for https://singhsidhukuldeep.github.io","text":"<p>Welcome to https://singhsidhukuldeep.github.io/ </p> <p>For any information, request or official correspondence please email to: singhsidhukuldeep@gmail.com</p> <p>Mailing Address:</p> <p>Kuldeep Singh Sidhu</p> <p>Street No 4, Malviya Nagar Bathinda, Punjab, 151001 India</p>"},{"location":"contact/#follow-on-social-media","title":"Follow on Social Media","text":"Platform Link GitHub https://github.com/singhsidhukuldeep LinkedIn https://www.linkedin.com/in/singhsidhukuldeep/ Twitter (X) https://twitter.com/kuldeep_s_s HuggingFace https://huggingface.co/singhsidhukuldeep StackOverflow https://stackoverflow.com/users/7182350 Website http://kuldeepsinghsidhu.com/"},{"location":"privacy/","title":"Privacy Policy for https://singhsidhukuldeep.github.io","text":""},{"location":"privacy/#introduction","title":"Introduction","text":"<p>Welcome to https://singhsidhukuldeep.github.io/ (the \"Website\"). Your privacy is important to us, and we are committed to protecting the personal information you share with us. This Privacy Policy explains how we collect, use, and disclose your information, and our commitment to ensuring that your personal data is handled with care and security.</p> <p>This policy complies with the General Data Protection Regulation (GDPR), ePrivacy Directive (EPD), California Privacy Rights Act (CPRA), Colorado Privacy Act (CPA), Virginia Consumer Data Protection Act (VCDPA), and Brazil's Lei Geral de Prote\u00e7\u00e3o de Dados (LGPD).</p>"},{"location":"privacy/#information-we-collect","title":"Information We Collect","text":""},{"location":"privacy/#personal-information","title":"Personal Information","text":"<p>We may collect personally identifiable information about you, such as:</p> <ul> <li>Name</li> <li>Email address</li> <li>IP address</li> <li>Other information you voluntarily provide through contact forms or interactions with the Website</li> </ul>"},{"location":"privacy/#non-personal-information","title":"Non-Personal Information","text":"<p>We may also collect non-personal information such as:</p> <ul> <li>Browser type</li> <li>Language preference</li> <li>Referring site</li> <li>Date and time of each visitor request</li> <li>Aggregated data on how visitors use the Website</li> </ul>"},{"location":"privacy/#cookies-and-web-beacons","title":"Cookies and Web Beacons","text":"<p>Our Website uses cookies to enhance your experience. A cookie is a small file that is placed on your device when you visit our Website. Cookies help us to:</p> <ul> <li>Remember your preferences and settings</li> <li>Understand how you interact with our Website</li> <li>Track and analyze usage patterns</li> </ul> <p>You can disable cookies through your browser settings; however, doing so may affect your ability to access certain features of the Website.</p>"},{"location":"privacy/#google-adsense","title":"Google AdSense","text":"<p>We use Google AdSense to display advertisements on our Website. Google AdSense may use cookies and web beacons to collect information about your interaction with the ads displayed on our Website. This information may include:</p> <ul> <li>Your IP address</li> <li>The type of browser you use</li> <li>The pages you visit on our Website</li> </ul> <p>Google may use this information to show you personalized ads based on your interests and browsing history. For more information on how Google uses your data, please visit the Google Privacy &amp; Terms page.</p>"},{"location":"privacy/#legal-bases-for-processing-your-data-gdpr-compliance","title":"Legal Bases for Processing Your Data (GDPR Compliance)","text":"<p>We process your personal data under the following legal bases:</p> <ul> <li>Consent: When you have given explicit consent for us to process your data for specific purposes.</li> <li>Contract: When processing your data is necessary to fulfill a contract with you or to take steps at your request before entering into a contract.</li> <li>Legitimate Interests: When the processing is necessary for our legitimate interests, such as improving our services, provided these are not overridden by your rights.</li> <li>Compliance with Legal Obligations: When we need to process your data to comply with a legal obligation.</li> </ul>"},{"location":"privacy/#how-your-data-will-be-used-to-show-ads","title":"How Your Data Will Be Used to Show Ads","text":"<p>We work with third-party vendors, including Google, to serve ads on our Website. These vendors use cookies and similar technologies to collect and use data about your visits to this and other websites to show you ads that are more relevant to your interests.</p>"},{"location":"privacy/#types-of-data-used","title":"Types of Data Used","text":"<p>The data used to show you ads may include:</p> <ul> <li>Demographic Information: Age, gender, and other demographic details</li> <li>Location Data: Approximate geographical location based on your IP address</li> <li>Behavioral Data: Your browsing behavior, such as pages visited, links clicked, and time spent on our Website</li> <li>Interests and Preferences: Based on your browsing history, the types of ads you interact with, and your preferences across websites</li> </ul>"},{"location":"privacy/#purpose-of-data-usage","title":"Purpose of Data Usage","text":"<p>The primary purpose of collecting and using this data is to:</p> <ul> <li>Serve ads that are relevant and tailored to your interests</li> <li>Improve ad targeting and effectiveness</li> <li>Analyze and optimize the performance of ads on our Website</li> </ul>"},{"location":"privacy/#opting-out-of-personalized-ads","title":"Opting Out of Personalized Ads","text":"<p>You can opt out of personalized ads by adjusting your ad settings with Google and other third-party vendors. For more information on how to opt out of personalized ads, please visit the Google Ads Settings page and review the options available to manage your preferences.</p>"},{"location":"privacy/#data-subject-rights-gdpr-cpra-cpa-vcdpa-lgpd-compliance","title":"Data Subject Rights (GDPR, CPRA, CPA, VCDPA, LGPD Compliance)","text":"<p>Depending on your jurisdiction, you have the following rights regarding your personal data:</p>"},{"location":"privacy/#right-to-access","title":"Right to Access","text":"<p>You have the right to request access to the personal data we hold about you and to receive a copy of this data.</p>"},{"location":"privacy/#right-to-rectification","title":"Right to Rectification","text":"<p>You have the right to request that we correct any inaccuracies in the personal data we hold about you.</p>"},{"location":"privacy/#right-to-erasure-right-to-be-forgotten","title":"Right to Erasure (Right to Be Forgotten)","text":"<p>You have the right to request that we delete your personal data, subject to certain conditions and legal obligations.</p>"},{"location":"privacy/#right-to-restriction-of-processing","title":"Right to Restriction of Processing","text":"<p>You have the right to request that we restrict the processing of your personal data in certain circumstances, such as when you contest the accuracy of the data.</p>"},{"location":"privacy/#right-to-data-portability","title":"Right to Data Portability","text":"<p>You have the right to receive your personal data in a structured, commonly used, and machine-readable format and to transmit this data to another controller.</p>"},{"location":"privacy/#right-to-object","title":"Right to Object","text":"<p>You have the right to object to the processing of your personal data based on legitimate interests or for direct marketing purposes.</p>"},{"location":"privacy/#right-to-withdraw-consent","title":"Right to Withdraw Consent","text":"<p>Where we rely on your consent to process your personal data, you have the right to withdraw your consent at any time.</p>"},{"location":"privacy/#right-to-non-discrimination-cpra-compliance","title":"Right to Non-Discrimination (CPRA Compliance)","text":"<p>We will not discriminate against you for exercising any of your privacy rights under CPRA or any other applicable laws.</p>"},{"location":"privacy/#exercising-your-rights","title":"Exercising Your Rights","text":"<p>To exercise any of these rights, please contact us at:</p> <p>Email: singhsidhukuldeep@gmail.com</p> <p>We will respond to your request within the timeframes required by applicable law.</p>"},{"location":"privacy/#how-we-use-your-information","title":"How We Use Your Information","text":"<p>We use the information collected from you to:</p> <ul> <li>Improve the content and functionality of our Website</li> <li>Display relevant advertisements through Google AdSense and other ad networks</li> <li>Respond to your inquiries and provide customer support</li> <li>Analyze usage patterns and improve our services</li> </ul>"},{"location":"privacy/#data-sharing-and-disclosure","title":"Data Sharing and Disclosure","text":""},{"location":"privacy/#third-party-service-providers","title":"Third-Party Service Providers","text":"<p>We may share your personal data with third-party service providers who assist us in operating our Website, conducting our business, or servicing you, as long as these parties agree to keep this information confidential.</p>"},{"location":"privacy/#legal-obligations","title":"Legal Obligations","text":"<p>We may disclose your personal data when required by law or to comply with legal processes, such as a court order or subpoena.</p>"},{"location":"privacy/#business-transfers","title":"Business Transfers","text":"<p>In the event of a merger, acquisition, or sale of all or a portion of our assets, your personal data may be transferred to the acquiring entity.</p>"},{"location":"privacy/#data-retention","title":"Data Retention","text":"<p>We will retain your personal data only for as long as necessary to fulfill the purposes outlined in this Privacy Policy unless a longer retention period is required or permitted by law.</p>"},{"location":"privacy/#data-security","title":"Data Security","text":"<p>We take reasonable measures to protect your information from unauthorized access, alteration, disclosure, or destruction. However, no method of transmission over the internet or electronic storage is 100% secure, and we cannot guarantee absolute security.</p>"},{"location":"privacy/#cross-border-data-transfers","title":"Cross-Border Data Transfers","text":"<p>Your personal data may be transferred to, and processed in, countries other than the country in which you are resident. These countries may have data protection laws that are different from the laws of your country.</p> <p>Where we transfer your personal data to other countries, we will take appropriate measures to ensure that your personal data remains protected in accordance with this Privacy Policy and applicable data protection laws.</p>"},{"location":"privacy/#your-consent","title":"Your Consent","text":"<p>By using our Website, you consent to our Privacy Policy and agree to its terms.</p>"},{"location":"privacy/#changes-to-this-privacy-policy","title":"Changes to This Privacy Policy","text":"<p>We may update this Privacy Policy from time to time. We will notify you of any changes by posting the new Privacy Policy on this page. You are advised to review this Privacy Policy periodically for any changes.</p>"},{"location":"privacy/#contact-us","title":"Contact Us","text":"<p>If you have any questions about this Privacy Policy, or if you would like to exercise your rights under GDPR, CPRA, CPA, VCDPA, or LGPD, please contact us at:</p> <p>Email: singhsidhukuldeep@gmail.com</p> <p>Mailing Address:</p> <p>Kuldeep Singh Sidhu</p> <p>Street No 4, Malviya Nagar Bathinda, Punjab, 151001 India</p>"},{"location":"projects/","title":"Projects","text":""},{"location":"projects/#introduction","title":"Introduction","text":"<p>These are the projects that you can take inspiration from and try to improve on them. \u270d\ufe0f</p> <p></p>"},{"location":"projects/#popular-sources","title":"Popular Sources","text":""},{"location":"projects/#list-of-projects","title":"List of projects","text":""},{"location":"projects/#natural-language-processing-nlp","title":"Natural Language processing (NLP)","text":"Title Description Source Author Text Classification with Facebook fasttext Building the User Review Model with fastText (Text Classification) with response time of less than one second Kuldeep Singh Sidhu Chat-bot using ChatterBot ChatterBot is a Python library that makes it easy to generate automated responses to a user\u2019s input. Kuldeep Singh Sidhu Text Summarizer Comparing state of the art models for text summary generation Kuldeep Singh Sidhu NLP with Spacy Building NLP pipeline using Spacy Kuldeep Singh Sidhu"},{"location":"projects/#recommendation-engine","title":"Recommendation Engine","text":"Title Description Source Author Recommendation Engine with Surprise Comparing different recommendation systems algorithms like SVD, SVDpp (Matrix Factorization), KNN Baseline, KNN Basic, KNN Means, KNN ZScore), Baseline, Co Clustering Kuldeep Singh Sidhu"},{"location":"projects/#image-processing","title":"Image Processing","text":"Title Description Source Author Facial Landmarks Using Dlib, a library capable of giving you 68 points (land marks) of the face. Kuldeep Singh Sidhu"},{"location":"projects/#reinforcement-learning","title":"Reinforcement Learning","text":"Title Description Source Author Google Dopamine Dopamine is a research framework for fast prototyping of reinforcement learning algorithms. Kuldeep Singh Sidhu Tic Tac Toe Training a computer to play Tic Tac Toe using reinforcement learning algorithms. Kuldeep Singh Sidhu"},{"location":"projects/#others","title":"Others","text":"Title Description Source Author TensorFlow Eager Execution Eager Execution (EE) enables you to run operations immediately. Kuldeep Singh Sidhu"},{"location":"Cheat-Sheets/Hypothesis-Tests/","title":"Hypothesis Tests in Python","text":"<p>A\u00a0statistical hypothesis test\u00a0is a method of\u00a0statistical inference\u00a0used to decide whether the data at hand sufficiently support a particular hypothesis. Hypothesis testing allows us to make probabilistic statements about population parameters.</p> <p>Few Notes:</p> <ul> <li>When it comes to assumptions such as the expected distribution of data or sample size, the results of a given test are likely to degrade gracefully rather than become immediately unusable if an assumption is violated.</li> <li>Generally, data samples need to be representative of the domain and large enough to expose their distribution to analysis.</li> <li>In some cases, the data can be corrected to meet the assumptions, such as correcting a nearly normal distribution to be normal by removing outliers, or using a correction to the degrees of freedom in a statistical test when samples have differing variance, to name two examples.</li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#normality-tests","title":"Normality Tests","text":"<p>This section lists statistical tests that you can use to check if your data has a Gaussian distribution.</p> <p>Gaussian distribution (also known as normal distribution) is a bell-shaped curve.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#shapiro-wilk-test","title":"Shapiro-Wilk Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Shapiro-Wilk Normality Test\nfrom scipy.stats import shapiro\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nstat, p = shapiro(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.shapiro</li> <li>Shapiro-Wilk test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#dagostinos-k2-test","title":"D\u2019Agostino\u2019s K^2 Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the D'Agostino's K^2 Normality Test\nfrom scipy.stats import normaltest\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nstat, p = normaltest(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.normaltest</li> <li>D'Agostino's K-squared test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#anderson-darling-test","title":"Anderson-Darling Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Anderson-Darling Normality Test\nfrom scipy.stats import anderson\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nresult = anderson(data)\nprint('stat=%.3f' % (result.statistic))\nfor i in range(len(result.critical_values)):\n    sl, cv = result.significance_level[i], result.critical_values[i]\n    if result.statistic &lt; cv:\n        print('Probably Gaussian at the %.1f%% level' % (sl))\n    else:\n        print('Probably not Gaussian at the %.1f%% level' % (sl))\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.anderson</li> <li>Anderson-Darling test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#correlation-tests","title":"Correlation Tests","text":"<p>This section lists statistical tests that you can use to check if two samples are related.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#pearsons-correlation-coefficient","title":"Pearson\u2019s Correlation Coefficient","text":"<p>Tests whether two samples have a linear relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Pearson's Correlation test\nfrom scipy.stats import pearsonr\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = pearsonr(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.pearsonr</li> <li>Pearson's correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#spearmans-rank-correlation","title":"Spearman\u2019s Rank Correlation","text":"<p>Tests whether two samples have a monotonic relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Spearman's Rank Correlation Test\nfrom scipy.stats import spearmanr\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = spearmanr(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.spearmanr</li> <li>Spearman's rank correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kendalls-rank-correlation","title":"Kendall\u2019s Rank Correlation","text":"<p>Tests whether two samples have a monotonic relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kendall's Rank Correlation Test\nfrom scipy.stats import kendalltau\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = kendalltau(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.kendalltau</li> <li>Kendall rank correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#chi-squared-test","title":"Chi-Squared Test","text":"<p>Tests whether two categorical variables are related or independent.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations used in the calculation of the contingency table are independent.</li> <li>25 or more examples in each cell of the contingency table.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Chi-Squared Test\nfrom scipy.stats import chi2_contingency\ntable = [[10, 20, 30],[6,  9,  17]]\nstat, p, dof, expected = chi2_contingency(table)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.chi2_contingency</li> <li>Chi-Squared test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#stationary-tests","title":"Stationary Tests","text":"<p>This section lists statistical tests that you can use to check if a time series is stationary or not.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#augmented-dickey-fuller-unit-root-test","title":"Augmented Dickey-Fuller Unit Root Test","text":"<p>Tests whether a time series has a unit root, e.g. has a trend or more generally is autoregressive.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in are temporally ordered.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: a unit root is present (series is non-stationary).</li> <li>H1: a unit root is not present (series is stationary).</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Augmented Dickey-Fuller unit root test\nfrom statsmodels.tsa.stattools import adfuller\ndata = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nstat, p, lags, obs, crit, t = adfuller(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably not Stationary')\nelse:\n    print('Probably Stationary')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>statsmodels.tsa.stattools.adfuller API.</li> <li>Augmented Dickey--Fuller test, Wikipedia.</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kwiatkowski-phillips-schmidt-shin","title":"Kwiatkowski-Phillips-Schmidt-Shin","text":"<p>Tests whether a time series is trend stationary or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in are temporally ordered.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the time series is trend-stationary.</li> <li>H1: the time series is not trend-stationary.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kwiatkowski-Phillips-Schmidt-Shin test\nfrom statsmodels.tsa.stattools import kpss\ndata = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nstat, p, lags, crit = kpss(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Stationary')\nelse:\n    print('Probably not Stationary')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>statsmodels.tsa.stattools.kpss API.</li> <li>KPSS test, Wikipedia.</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#parametric-statistical-hypothesis-tests","title":"Parametric Statistical Hypothesis Tests","text":"<p>This section lists statistical tests that you can use to compare data samples.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#students-t-test","title":"Student\u2019s t-test","text":"<p>Tests whether the means of two independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Student's t-test\nfrom scipy.stats import ttest_ind\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = ttest_ind(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.ttest_ind</li> <li>Student's t-test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#paired-students-t-test","title":"Paired Student\u2019s t-test","text":"<p>Tests whether the means of two independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Paired Student's t-test\nfrom scipy.stats import ttest_rel\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = ttest_rel(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.ttest_rel</li> <li>Student's t-test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#analysis-of-variance-test-anova","title":"Analysis of Variance Test (ANOVA)","text":"<p>Tests whether the means of two or more independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Analysis of Variance Test\nfrom scipy.stats import f_oneway\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\ndata3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\nstat, p = f_oneway(data1, data2, data3)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.f_oneway</li> <li>Analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#repeated-measures-anova-test","title":"Repeated Measures ANOVA Test","text":"<p>Tests whether the means of two or more paired samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: one or more of the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Currently not supported in Python. :(\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>Analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#nonparametric-statistical-hypothesis-tests","title":"Nonparametric Statistical Hypothesis Tests","text":"<p>In Non-Parametric tests, we don't make any assumption about the parameters for the given population or the population we are studying. In fact, these tests don't depend on the population. Hence, there is no fixed set of parameters is available, and also there is no distribution (normal distribution, etc.)</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#mann-whitney-u-test","title":"Mann-Whitney U Test","text":"<p>Tests whether the distributions of two independent samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of both samples are equal.</li> <li>H1: the distributions of both samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Mann-Whitney U Test\nfrom scipy.stats import mannwhitneyu\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = mannwhitneyu(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.mannwhitneyu</li> <li>Mann-Whitney U test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#wilcoxon-signed-rank-test","title":"Wilcoxon Signed-Rank Test","text":"<p>Tests whether the distributions of two paired samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of both samples are equal.</li> <li>H1: the distributions of both samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Wilcoxon Signed-Rank Test\nfrom scipy.stats import wilcoxon\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = wilcoxon(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.wilcoxon</li> <li>Wilcoxon signed-rank test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kruskal-wallis-h-test","title":"Kruskal-Wallis H Test","text":"<p>Tests whether the distributions of two or more independent samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of all samples are equal.</li> <li>H1: the distributions of one or more samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kruskal-Wallis H Test\nfrom scipy.stats import kruskal\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = kruskal(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.kruskal</li> <li>Kruskal-Wallis one-way analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#friedman-test","title":"Friedman Test","text":"<p>Tests whether the distributions of two or more paired samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of all samples are equal.</li> <li>H1: the distributions of one or more samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Friedman Test\nfrom scipy.stats import friedmanchisquare\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\ndata3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\nstat, p = friedmanchisquare(data1, data2, data3)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.friedmanchisquare</li> <li>Friedman test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#equality-of-variance-test","title":"Equality of variance test","text":"<p>Test is used to assess the equality of variance between two different samples.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#levenes-test","title":"Levene's test","text":"<p>Levene\u2019s test is used to assess the equality of variance between two or more different samples.</p> <ul> <li> <p>Assumptions</p> <ul> <li>The samples from the populations under consideration are independent.</li> <li>The populations under consideration are approximately normally distributed.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: All the samples variances are equal</li> <li>H1: At least one variance is different from the rest</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Levene's test\nfrom scipy.stats import levene\na = [8.88, 9.12, 9.04, 8.98, 9.00, 9.08, 9.01, 8.85, 9.06, 8.99]\nb = [8.88, 8.95, 9.29, 9.44, 9.15, 9.58, 8.36, 9.18, 8.67, 9.05]\nc = [8.95, 9.12, 8.95, 8.85, 9.03, 8.84, 9.07, 8.98, 8.86, 8.98]\nstat, p = levene(a, b, c)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same variances')\nelse:\n    print('Probably at least one variance is different from the rest')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.levene</li> <li>Levene's test on Wikipedia</li> </ul> </li> </ul> <p>Source: https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/</p>"},{"location":"Deploying-ML-models/deploying-ml-models/","title":"Home","text":""},{"location":"Deploying-ML-models/deploying-ml-models/#introduction","title":"Introduction","text":"<p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#contribute-to-the-platform","title":"Contribute to the platform","text":"<p>Contribution in any form will be deeply appreciated. \ud83d\ude4f</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#add-questions","title":"Add questions","text":"<p>\u2753 Add your questions here. Please ensure to provide a detailed description to allow your fellow contributors to understand your questions and answer them to your satisfaction.</p> <p></p> <p>\ud83e\udd1d Please note that as of now, you cannot directly add a question via a pull request. This will help us to maintain the quality of the content for you.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#add-answerstopics","title":"Add answers/topics","text":"<p>\ud83d\udcdd These are the answers/topics that need your help at the moment</p> <ul> <li> Add documentation for the project</li> <li> Online Material for Learning</li> <li> Suggested Learning Paths</li> <li> Cheat Sheets<ul> <li> Django</li> <li> Flask</li> <li> Numpy</li> <li> Pandas</li> <li> PySpark</li> <li> Python</li> <li> RegEx</li> <li> SQL</li> </ul> </li> <li> NLP Interview Questions</li> <li> Add python common DSA interview questions</li> <li> Add Major ML topics<ul> <li> Linear Regression </li> <li> Logistic Regression </li> <li> SVM </li> <li> Random Forest </li> <li> Gradient boosting </li> <li> PCA </li> <li> Collaborative Filtering </li> <li> K-means clustering </li> <li> kNN </li> <li> ARIMA </li> <li> Neural Networks </li> <li> Decision Trees </li> <li> Overfitting, Underfitting</li> <li> Unbalanced, Skewed data</li> <li> Activation functions relu/ leaky relu</li> <li> Normalization</li> <li> DBSCAN </li> <li> Normal Distribution </li> <li> Precision, Recall </li> <li> Loss Function MAE, RMSE </li> </ul> </li> <li> Add Pandas questions</li> <li> Add NumPy questions</li> <li> Add TensorFlow questions</li> <li> Add PyTorch questions</li> <li> Add list of learning resources</li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#reportsolve-issues","title":"Report/Solve Issues","text":"<p>\ud83d\udd27 To report any issues find me on LinkedIn or raise an issue on GitHub.</p> <p>\ud83d\udee0 You can also solve existing issues on GitHub and create a pull request.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#say-thanks","title":"Say Thanks","text":"<p>\ud83d\ude0a If this platform helped you in any way, it would be great if you could share it with others.</p> <p> </p> <pre><code>Check out this \ud83d\udc47 platform \ud83d\udc47 for data science content:\n\ud83d\udc49 https://singhsidhukuldeep.github.io/data-science-interview-prep/ \ud83d\udc48\n\n#data-science #machine-learning #interview-preparation \n</code></pre> <p>You can also star the repository on GitHub    and watch-out for any updates </p>"},{"location":"Deploying-ML-models/deploying-ml-models/#features","title":"Features","text":"<ul> <li> <p>\ud83c\udfa8 Beautiful: The design is built on top of most popular libraries like MkDocs and material which allows the platform to be responsive and to work on all sorts of devices \u2013 from mobile phones to wide-screens. The underlying fluid layout will always adapt perfectly to the available screen space.</p> </li> <li> <p>\ud83e\uddd0 Searchable: almost magically, all the content on the website is searchable without any further ado. The built-in search \u2013 server-less \u2013 is fast and accurate in responses to any of the queries.</p> </li> <li> <p>\ud83d\ude4c Accessible:</p> <ul> <li>Easy to use: \ud83d\udc4c The website is hosted on github-pages and is free and open to use to over 40 million users of GitHub in 100+ countries.</li> <li>Easy to contribute: \ud83e\udd1d The website embodies the concept of collaboration to the latter. Allowing anyone to add/improve the content. To make contributing easy, everything is written in MarkDown and then compiled to beautiful html.</li> </ul> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#setup","title":"Setup","text":"<p>No setup is required for usage of the platform</p> <p>Important: It is strongly advised to use virtual environment and not change anything in <code>gh-pages</code></p>"},{"location":"Deploying-ML-models/deploying-ml-models/#linux-systems","title":"<code>Linux</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nsource venv/bin/activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>deactivate\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#windows-systems","title":"<code>Windows</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nvenv\\Scripts\\activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>venv\\Scripts\\deactivate\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#to-install-the-latest","title":"To install the latest","text":"<pre><code>pip3 install mkdocs\npip3 install mkdocs-material\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#useful-commands","title":"Useful Commands","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Use\u00a0<code>mkdocs gh-deploy --help</code>\u00a0to get a full list of options available for the\u00a0<code>gh-deploy</code>\u00a0command.     Be aware that you will not be able to review the built site before it is pushed to GitHub. Therefore, you may want to verify any changes you make to the docs beforehand by using the\u00a0<code>build</code>\u00a0or\u00a0<code>serve</code>\u00a0commands and reviewing the built files locally.</li> <li><code>mkdocs new [dir-name]</code> - Create a new project. No need to create a new project</li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#useful-documents","title":"Useful Documents","text":"<ul> <li> <p>\ud83d\udcd1 MkDocs: https://github.com/mkdocs/mkdocs</p> </li> <li> <p>\ud83c\udfa8 Theme: https://github.com/squidfunk/mkdocs-material</p> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#faq","title":"FAQ","text":"<ul> <li> <p>Can I filter questions based on companies? \ud83e\udd2a</p> <p>As much as this platform aims to help you with your interview preparation, it is not a short-cut to crack one. Think of this platform as a practicing field to help you sharpen your skills for your interview processes. However, for your convenience we have sorted all the questions by topics for you. \ud83e\udd13</p> <p>This doesn't mean that such feature won't be added in the future.  \"Never say Never\"</p> <p>But as of now there is neither plan nor data to do so. \ud83d\ude22</p> </li> <li> <p>Why is this platform free? \ud83e\udd17</p> <p>Currently there is no major cost involved in maintaining this platform other than time and effort that is put in by every contributor.  If you want to help you can contribute here. </p> <p>If you still want to pay for something that is free, we would request you to donate it to a charity of your choice instead. \ud83d\ude07</p> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#credits","title":"Credits","text":""},{"location":"Deploying-ML-models/deploying-ml-models/#maintained-by","title":"Maintained by","text":"<p>\ud83d\udc68\u200d\ud83c\udf93 Kuldeep Singh Sidhu </p> <p>Github: github/singhsidhukuldeep <code>https://github.com/singhsidhukuldeep</code></p> <p>Website: Kuldeep Singh Sidhu (Website) <code>http://kuldeepsinghsidhu.com</code></p> <p>LinkedIn: Kuldeep Singh Sidhu (LinkedIn) <code>https://www.linkedin.com/in/singhsidhukuldeep/</code></p>"},{"location":"Deploying-ML-models/deploying-ml-models/#contributors","title":"Contributors","text":"<p>\ud83d\ude0e The full list of all the contributors is available here</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#current-status","title":"Current Status","text":""},{"location":"Interview-Questions/Interview-Questions/","title":"Interview Questions (Intro)","text":"<p>These are currently most commonly asked questions. Questions can be removed if they are no longer popular in interview circles and added as new question banks are released.</p>"},{"location":"Interview-Questions/Natural-Language-Processing/","title":"NLP Interview Questions","text":""},{"location":"Interview-Questions/Probability/","title":"Probability Interview Questions","text":"<ul> <li>Probability Interview Questions<ul> <li>Average score on a dice role of at most 3 times</li> </ul> </li> </ul>"},{"location":"Interview-Questions/Probability/#average-score-on-a-dice-role-of-at-most-3-times","title":"Average score on a dice role of at most 3 times","text":"<p>Question</p> <p>Consider a fair 6-sided dice.  Your aim is to get the highest score you can, in at-most 3 roles.</p> <p>A score is defined as the number that appears on the face of the dice facing up after the role.  You can role at most 3 times but every time you role it is up to you to decide whether you want to role again.</p> <p>The last score will be counted as your final score.</p> <ul> <li>Find the average score if you rolled the dice only once?</li> <li>Find the average score that you can get with at most 3 roles?</li> <li>If the dice is fair, why is the average score for at most 3 roles and 1 role not the same?</li> </ul> Hint 1 <p>Find what is the expected score on single role</p> <p>And for cases when scores of single role &lt; <code>expected score on single role</code>  is when you will go for next role</p> <p>Eg: if expected score of single role comes out to be 4.5,  you will only role next turn for 1,2,3,4 and not for 5,6</p> Answer <p>If you role a fair dice once you can get:</p> Score Probability 1 \u2159 2 \u2159 3 \u2159 4 \u2159 5 \u2159 6 \u2159 <p>So your average score with one role is: </p> <p><code>sum of(score * scores's probability)</code> = (1+2+3+4+5+6)*(\u2159) = (21/6) = 3.5</p> <p>The average score if you rolled the dice only once is 3.5</p> <p>For at most 3 roles, let's try back-tracking. Let's say just did your second role and you have to decide whether to do your 3<sup>rd</sup> role!</p> <p>We just found out if we role dice once on average we can expect score of 3.5. So we will only role the 3<sup>rd</sup> time if score on 2<sup>nd</sup> role is less than 3.5 i.e (1,2 or 3)</p> <p>Possibilities</p> 2<sup>nd</sup> role score Probability 3<sup>rd</sup> role score Probability 1 \u2159 3.5 \u2159 2 \u2159 3.5 \u2159 3 \u2159 3.5 \u2159 4 \u2159 NA We won't role 5 \u2159 NA 3<sup>rd</sup> time if we 6 \u2159 NA get score &gt;3 on 2<sup>nd</sup> <p>So if we had 2 roles, average score would be:</p> <pre><code>[We role again if current score is less than 3.4]\n(3.5)*(1/6) + (3.5)*(1/6) + (3.5)*(1/6) \n+\n(4)*(1/6) + (5)*(1/6) + (6)*(1/6) [Decide not to role again]\n=\n1.75 + 2.5 = 4.25\n</code></pre> <p>The average score if you rolled the dice twice is 4.25</p> <p>So now if we look from the perspective of first role. We will only role again if our score is less than 4.25 i.e 1,2,3 or 4</p> <p>Possibilities</p> 1<sup>st</sup> role score Probability 2<sup>nd</sup> and 3<sup>rd</sup> role score Probability 1 \u2159 4.25 \u2159 2 \u2159 4.25 \u2159 3 \u2159 4.25 \u2159 4 \u2159 4.25 \u2159 5 \u2159 NA We won't role again if we 6 \u2159 NA get score &gt;4.25 on 1<sup>st</sup> <p>So if we had 3 roles, average score would be:</p> <p><pre><code>[We role again if current score is less than 4.25]\n(4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) \n+\n(5)*(1/6) + (6)*(1/6) [[Decide not to role again]\n=\n17/6 + 11/6 = 4.66\n</code></pre> The average score if you rolled the dice only once is 4.66</p> <p>The average score for at most 3 roles and 1 role is not the same because although the dice is fair the event of rolling the dice is no longer independent. The scores would have been the same if we rolled the dice 2<sup>nd</sup> and 3<sup>rd</sup> time without considering what we got in the last roll i.e. if the event of rolling the dice was independent.</p>"},{"location":"Interview-Questions/System-design/","title":"System Design","text":""},{"location":"Interview-Questions/data-structures-algorithms/","title":"Data Structure and Algorithms (DSA)","text":"<ul> <li>Data Structure and Algorithms (DSA)<ul> <li>To-do</li> <li>\ud83d\ude01 Easy<ul> <li>Two Number Sum</li> <li>Validate Subsequence</li> <li>Nth Fibonacci</li> <li>Product Sum</li> </ul> </li> <li>\ud83d\ude42 Medium<ul> <li>Top K Frequent Words</li> </ul> </li> <li>\ud83e\udd28 Hard</li> <li>\ud83d\ude32 Very Hard</li> </ul> </li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#to-do","title":"To-do","text":"<ul> <li> Add https://leetcode.com/discuss/interview-question/344650/Amazon-Online-Assessment-Questions</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#easy","title":"\ud83d\ude01 Easy","text":""},{"location":"Interview-Questions/data-structures-algorithms/#two-number-sum","title":"Two Number Sum","text":"<p>Question</p> <p>Write a function that takes in a non-empty array of distinct integers and an integer representing a target sum. </p> <p>If any two numbers in the input array sum up to the target sum, the function should return them in an array, in any order. </p> <p>If no two numbers sum up to the target sum, the function should return an empty array.</p> Try it! <ul> <li>LeetCode: https://leetcode.com/problems/two-sum/</li> </ul> Hint 1 <p>No Hint</p> Answer <p><pre><code># O(n) time | O(n) space\ndef twoNumberSum(array, targetSum):\n    avail = set()\n    for i,v in enumerate(array):\n        if targetSum-v in avail:\n            return [targetSum-v,v]\n        else:\n            avail.add(v)\n    return []\n    pass\n</code></pre> <pre><code># O(nlog(n)) time | O(1) space\ndef twoNumberSum(array, targetSum):\n    array.sort()\n    n = len(array)\n    left = 0\n    right = n-1\n    while left&lt;right:\n        currSum = array[left]+array[right]\n        if currSum==targetSum: return [array[left], array[right]]\n        elif currSum&lt;targetSum: left+=1\n        elif currSum&gt;targetSum: right-=1\n    return []\n    pass\n</code></pre> <pre><code># O(n^2) time | O(1) space\ndef twoNumberSum(array, targetSum):\n    n = len(array)\n    for i in range(n-1):\n        for j in range(i+1,n):\n            if array[i]+array[j] == targetSum:\n                return [array[i],array[j]]\n    return []\n    pass\n</code></pre></p>"},{"location":"Interview-Questions/data-structures-algorithms/#validate-subsequence","title":"Validate Subsequence","text":"<p>Question</p> <p>Given two non-empty arrays of integers, write a function that determines whether the second array is a subsequence of the first one.</p> <p>A subsequence of an array is a set of numbers that aren't necessarily adjacent in the array but that are in the same order as they appear in the array. For instance, the numbers [1, 3, 4]  form a subsequence of the array [1, 2, 3, 4] , and so do the numbers [2, 4].</p> <p>Note that a single number in an array and the array itself are both valid subsequences of the array.</p> Try it! <ul> <li>GeeksforGeeks: https://www.geeksforgeeks.org/problems/array-subset-of-another-array2317/1</li> </ul> Hint 1 <p>No Hint</p> Answer <pre><code># O(n) time | O(1) space - where n is the length of the array\ndef isValidSubsequence(array, sequence):\n    pArray = pSequence = 0\n    while pArray &lt; len(array) and pSequence &lt; len(sequence):\n        if array[pArray] == sequence[pSequence]:\n            pArray+=1\n            pSequence+=1\n        else: pArray+=1\n    return pSequence == len(sequence)\n    pass\n</code></pre>"},{"location":"Interview-Questions/data-structures-algorithms/#nth-fibonacci","title":"Nth Fibonacci","text":"<p>Question</p> <p>The Fibonacci sequence is defined as follows: Any number in the sequence is the sum of the previous 2.</p> <p>for <code>fib[n] = fib[n-1] + fib[n-2]</code></p> <p>The 1<sup>st</sup> and 2<sup>nd</sup> are fixed at 0,1</p> <p>Find the nth Nth Fibonacci sequence</p> Try it! <ul> <li>LeetCode: https://leetcode.com/problems/fibonacci-number/</li> <li>GeeksforGeeks: https://www.geeksforgeeks.org/problems/nth-fibonacci-number1335/1</li> </ul> Hint 1 <p>No Hint</p> Answer <pre><code># O(n) time | O(n) space\ndef getNthFib(n):\n    dp = [0,1]\n    while len(dp)&lt;n:\n        dp.append(dp[-1]+dp[-2])\n    return dp[n-1]\n    pass\n</code></pre> <pre><code># O(n) time | O(1) space\ndef getNthFib(n):\n    last_two = [0,1]\n    count = 2\n    while count &lt; n:\n        currFib = last_two[0] + last_two[1]\n        last_two[0] = last_two[1]\n        last_two[1] = currFib\n        count += 1\n    return last_two[1] if n&gt;1 else last_two[0]\n    pass\n</code></pre>"},{"location":"Interview-Questions/data-structures-algorithms/#product-sum","title":"Product Sum","text":"<p>Question</p> <p>Write a function that takes in a \"special\" array and returns its product sum. A \"special\" array is a non-empty array that contains either integers or other \"special\" arrays. The product sum of a \"special\" array is the sum of its elements, where \"special\" arrays inside it are summed themselves and then multiplied by their level of depth.</p> <p>For example, the product sum of <code>[x, y]</code> is <code>x + y</code> ; the product sum of <code>[x, [y, z]]</code> is <code>x + 2y + 2z</code></p> <p>Eg: Input: <code>[5, 2, [7, -1], 3, [6, [-13, 8], 4]]</code> Output: <code>12 # calculated as: 5 + 2 + 2 * (7 - 1) + 3 + 2 * (6 + 3 * (-13 + 8) + 4)</code></p> Try it! <ul> <li>LeetCode: https://leetcode.com/problems/fibonacci-number/</li> <li>GeeksforGeeks: https://www.geeksforgeeks.org/problems/nth-fibonacci-number1335/1</li> </ul> Hint 1 <p>No Hint</p> Answer <pre><code># O(n) time | O(d) space - where n is the total number of elements in the array,\n# including sub-elements, and d is the greatest depth of \"special\" arrays in the array\ndef productSum(array, depth = 1):\n    sum = 0\n    for i,v in enumerate(array):\n        if type(v) is list:\n            sum += productSum(v, depth + 1)\n        else:\n            sum += v\n    return sum*depth\n    pass\n</code></pre>"},{"location":"Interview-Questions/data-structures-algorithms/#medium","title":"\ud83d\ude42 Medium","text":""},{"location":"Interview-Questions/data-structures-algorithms/#top-k-frequent-words","title":"Top K Frequent Words","text":"<p>Question</p> <p>Given a non-empty list of words, return the\u00a0k\u00a0most frequent elements.</p> <p>Your answer should be sorted by frequency from highest to lowest. If two words have the same frequency, then the word with the lower alphabetical order comes first.</p> <p>Example 1:</p> <pre><code>Input: [\"i\", \"love\", \"leetcode\", \"i\", \"love\", \"coding\"], k = 2\nOutput: [\"i\", \"love\"]\nExplanation: \"i\" and \"love\" are the two most frequent words.\n    Note that \"i\" comes before \"love\" due to a lower alphabetical order.\n</code></pre> <p>Example 2:</p> <p><pre><code>Input: [\"the\", \"day\", \"is\", \"sunny\", \"the\", \"the\", \"the\", \"sunny\", \"is\", \"is\"], k = 4\nOutput: [\"the\", \"is\", \"sunny\", \"day\"]\nExplanation: \"the\", \"is\", \"sunny\" and \"day\" are the four most frequent words,\n    with the number of occurrence being 4, 3, 2 and 1 respectively.\n</code></pre> Note:</p> <ol> <li>You may assume\u00a0k\u00a0is always valid, 1 \u2264\u00a0k\u00a0\u2264 number of unique elements.</li> <li>Input words contain only lowercase letters.</li> </ol> <p>Follow up:</p> <ol> <li>Try to solve it in\u00a0O(n\u00a0log\u00a0k) time and\u00a0O(n) extra space.</li> </ol> Try it! <ul> <li>LeetCode: https://leetcode.com/problems/fibonacci-number/</li> <li>GeeksforGeeks: https://www.geeksforgeeks.org/problems/nth-fibonacci-number1335/1</li> </ul> Hint 1 <p>No Hint</p> Answer <pre><code># Count the frequency of each word, and \n# sort the words with a custom ordering relation \n# that uses these frequencies. Then take the best k of them.\n\n# Time Complexity: O(N \\log{N})O(NlogN), where NN is the length of words. \n# We count the frequency of each word in O(N)O(N) time, \n# then we sort the given words in O(N \\log{N})O(NlogN) time.\n# Space Complexity: O(N)O(N), the space used to store our uniqueWords.\ndef topKFrequentWords(words, k)-&gt; List[str]:\n    from collections import Counter\n    wordsFreq = Counter(words)\n    uniqueWords = list(wordsFreq.keys())\n    uniqueWords.sort(key = lambda x: (-wordsFreq[x], x))\n    return uniqueWords[:k]\n</code></pre> <pre><code># Time Complexity: O(N \\log{k})O(Nlogk), where NN is the length of words. \n# We count the frequency of each word in O(N)O(N) time, then we add NN words to the heap, \n# each in O(\\log {k})O(logk) time. Finally, we pop from the heap up to kk times. \n# As k \\leq Nk\u2264N, this is O(N \\log{k})O(Nlogk) in total.\n\n# In Python, we improve this to O(N + k \\log {N})O(N+klogN): our heapq.heapify operation and \n# counting operations are O(N)O(N), and \n# each of kk heapq.heappop operations are O(\\log {N})O(logN).\n\n# Space Complexity: O(N)O(N), the space used to store our wordsFreq.\n\n# Count the frequency of each word, then add it to heap that stores the best k candidates. \n# Here, \"best\" is defined with our custom ordering relation, \n# which puts the worst candidates at the top of the heap. \n# At the end, we pop off the heap up to k times and reverse the result \n# so that the best candidates are first.\n\n# In Python, we instead use heapq.heapify, which can turn a list into a heap in linear time, \n# simplifying our work.\n\ndef topKFrequentWords(words, k)-&gt; List[str]:\n    from heapq import heapify, heappop#, heappush\n    from collections import Counter\n    wordsFreq = Counter(words)\n    heap = [(-freq, word) for word, freq in wordsFreq.items()]\n    heapq.heapify(heap)\n    return [heapq.heappop(heap)[1] for _ in range(k)]\n</code></pre>"},{"location":"Interview-Questions/data-structures-algorithms/#hard","title":"\ud83e\udd28 Hard","text":""},{"location":"Interview-Questions/data-structures-algorithms/#very-hard","title":"\ud83d\ude32 Very Hard","text":""}]}